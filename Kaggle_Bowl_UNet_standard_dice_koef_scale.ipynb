{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [02:37<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:01<00:00, 54.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py:51: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  out_of_range_float = (np.issubdtype(image.dtype, np.float) and\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeafae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xebaf3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256, 256, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 16) 448         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256, 256, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 16) 2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 16) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 128, 32) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 32) 9248        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 64, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 256)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 256)  590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 128)  131200      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 128)  147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 64)   32832       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 64)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 32) 8224        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128, 128, 32) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 32) 9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 16) 2064        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256, 256, 16) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 16) 2320        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 1)  17          conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "603/603 [==============================] - ETA: 6:29 - loss: 0.7490 - dice_coef: 0.261 - ETA: 5:40 - loss: 0.6939 - dice_coef: 0.213 - ETA: 5:16 - loss: 0.6510 - dice_coef: 0.197 - ETA: 4:58 - loss: 0.6043 - dice_coef: 0.175 - ETA: 4:44 - loss: 0.5862 - dice_coef: 0.165 - ETA: 4:31 - loss: 0.5636 - dice_coef: 0.159 - ETA: 4:21 - loss: 0.5445 - dice_coef: 0.155 - ETA: 4:10 - loss: 0.5419 - dice_coef: 0.156 - ETA: 4:01 - loss: 0.5254 - dice_coef: 0.156 - ETA: 3:51 - loss: 0.5124 - dice_coef: 0.157 - ETA: 3:42 - loss: 0.4997 - dice_coef: 0.158 - ETA: 3:33 - loss: 0.4919 - dice_coef: 0.164 - ETA: 3:24 - loss: 0.4862 - dice_coef: 0.165 - ETA: 3:15 - loss: 0.4808 - dice_coef: 0.168 - ETA: 3:07 - loss: 0.4728 - dice_coef: 0.169 - ETA: 2:58 - loss: 0.4693 - dice_coef: 0.169 - ETA: 2:50 - loss: 0.4670 - dice_coef: 0.170 - ETA: 2:41 - loss: 0.4646 - dice_coef: 0.173 - ETA: 2:33 - loss: 0.4583 - dice_coef: 0.175 - ETA: 2:25 - loss: 0.4553 - dice_coef: 0.179 - ETA: 2:16 - loss: 0.4518 - dice_coef: 0.184 - ETA: 2:08 - loss: 0.4449 - dice_coef: 0.188 - ETA: 2:00 - loss: 0.4423 - dice_coef: 0.192 - ETA: 1:51 - loss: 0.4353 - dice_coef: 0.200 - ETA: 1:43 - loss: 0.4297 - dice_coef: 0.209 - ETA: 1:35 - loss: 0.4240 - dice_coef: 0.217 - ETA: 1:27 - loss: 0.4193 - dice_coef: 0.225 - ETA: 1:18 - loss: 0.4173 - dice_coef: 0.233 - ETA: 1:10 - loss: 0.4144 - dice_coef: 0.240 - ETA: 1:02 - loss: 0.4077 - dice_coef: 0.248 - ETA: 54s - loss: 0.4010 - dice_coef: 0.258 - ETA: 46s - loss: 0.3953 - dice_coef: 0.26 - ETA: 38s - loss: 0.3908 - dice_coef: 0.27 - ETA: 29s - loss: 0.3874 - dice_coef: 0.28 - ETA: 21s - loss: 0.3827 - dice_coef: 0.28 - ETA: 13s - loss: 0.3769 - dice_coef: 0.29 - ETA: 5s - loss: 0.3718 - dice_coef: 0.3040 - 317s 526ms/step - loss: 0.3701 - dice_coef: 0.3098 - val_loss: 0.2367 - val_dice_coef: 0.6094\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23665, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 2/50\n",
      "603/603 [==============================] - ETA: 4:52 - loss: 0.2229 - dice_coef: 0.528 - ETA: 4:46 - loss: 0.2347 - dice_coef: 0.527 - ETA: 4:38 - loss: 0.2220 - dice_coef: 0.540 - ETA: 4:30 - loss: 0.2127 - dice_coef: 0.543 - ETA: 4:21 - loss: 0.2447 - dice_coef: 0.530 - ETA: 4:14 - loss: 0.2443 - dice_coef: 0.543 - ETA: 4:06 - loss: 0.2595 - dice_coef: 0.542 - ETA: 3:58 - loss: 0.2563 - dice_coef: 0.546 - ETA: 3:49 - loss: 0.2503 - dice_coef: 0.554 - ETA: 3:41 - loss: 0.2502 - dice_coef: 0.546 - ETA: 3:33 - loss: 0.2564 - dice_coef: 0.539 - ETA: 3:25 - loss: 0.2512 - dice_coef: 0.540 - ETA: 3:17 - loss: 0.2521 - dice_coef: 0.538 - ETA: 3:09 - loss: 0.2533 - dice_coef: 0.535 - ETA: 3:01 - loss: 0.2512 - dice_coef: 0.536 - ETA: 2:53 - loss: 0.2490 - dice_coef: 0.541 - ETA: 2:45 - loss: 0.2493 - dice_coef: 0.546 - ETA: 2:37 - loss: 0.2500 - dice_coef: 0.549 - ETA: 2:29 - loss: 0.2471 - dice_coef: 0.551 - ETA: 2:21 - loss: 0.2473 - dice_coef: 0.548 - ETA: 2:13 - loss: 0.2446 - dice_coef: 0.546 - ETA: 2:05 - loss: 0.2428 - dice_coef: 0.547 - ETA: 1:57 - loss: 0.2414 - dice_coef: 0.545 - ETA: 1:49 - loss: 0.2392 - dice_coef: 0.547 - ETA: 1:41 - loss: 0.2386 - dice_coef: 0.549 - ETA: 1:33 - loss: 0.2364 - dice_coef: 0.553 - ETA: 1:25 - loss: 0.2352 - dice_coef: 0.554 - ETA: 1:17 - loss: 0.2331 - dice_coef: 0.559 - ETA: 1:09 - loss: 0.2306 - dice_coef: 0.562 - ETA: 1:01 - loss: 0.2284 - dice_coef: 0.564 - ETA: 53s - loss: 0.2272 - dice_coef: 0.566 - ETA: 45s - loss: 0.2286 - dice_coef: 0.56 - ETA: 37s - loss: 0.2261 - dice_coef: 0.57 - ETA: 29s - loss: 0.2239 - dice_coef: 0.57 - ETA: 21s - loss: 0.2220 - dice_coef: 0.57 - ETA: 13s - loss: 0.2223 - dice_coef: 0.57 - ETA: 5s - loss: 0.2208 - dice_coef: 0.5797 - 313s 519ms/step - loss: 0.2195 - dice_coef: 0.5815 - val_loss: 0.1686 - val_dice_coef: 0.6655\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23665 to 0.16856, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 3/50\n",
      "603/603 [==============================] - ETA: 5:33 - loss: 0.1270 - dice_coef: 0.592 - ETA: 5:22 - loss: 0.1752 - dice_coef: 0.607 - ETA: 5:06 - loss: 0.1992 - dice_coef: 0.601 - ETA: 4:56 - loss: 0.2056 - dice_coef: 0.603 - ETA: 4:45 - loss: 0.1998 - dice_coef: 0.618 - ETA: 4:36 - loss: 0.1918 - dice_coef: 0.627 - ETA: 4:27 - loss: 0.1910 - dice_coef: 0.638 - ETA: 4:18 - loss: 0.1838 - dice_coef: 0.647 - ETA: 4:08 - loss: 0.1784 - dice_coef: 0.656 - ETA: 4:01 - loss: 0.1788 - dice_coef: 0.663 - ETA: 3:52 - loss: 0.1830 - dice_coef: 0.663 - ETA: 3:42 - loss: 0.1861 - dice_coef: 0.667 - ETA: 3:32 - loss: 0.1828 - dice_coef: 0.671 - ETA: 3:23 - loss: 0.1821 - dice_coef: 0.676 - ETA: 3:14 - loss: 0.1775 - dice_coef: 0.682 - ETA: 3:04 - loss: 0.1753 - dice_coef: 0.684 - ETA: 2:56 - loss: 0.1726 - dice_coef: 0.686 - ETA: 2:47 - loss: 0.1709 - dice_coef: 0.687 - ETA: 2:38 - loss: 0.1669 - dice_coef: 0.689 - ETA: 2:29 - loss: 0.1689 - dice_coef: 0.688 - ETA: 2:20 - loss: 0.1685 - dice_coef: 0.689 - ETA: 2:12 - loss: 0.1659 - dice_coef: 0.691 - ETA: 2:03 - loss: 0.1640 - dice_coef: 0.690 - ETA: 1:54 - loss: 0.1649 - dice_coef: 0.691 - ETA: 1:46 - loss: 0.1653 - dice_coef: 0.691 - ETA: 1:37 - loss: 0.1660 - dice_coef: 0.691 - ETA: 1:29 - loss: 0.1671 - dice_coef: 0.692 - ETA: 1:21 - loss: 0.1669 - dice_coef: 0.693 - ETA: 1:12 - loss: 0.1664 - dice_coef: 0.696 - ETA: 1:04 - loss: 0.1648 - dice_coef: 0.698 - ETA: 55s - loss: 0.1637 - dice_coef: 0.699 - ETA: 47s - loss: 0.1634 - dice_coef: 0.69 - ETA: 39s - loss: 0.1617 - dice_coef: 0.70 - ETA: 30s - loss: 0.1601 - dice_coef: 0.70 - ETA: 22s - loss: 0.1591 - dice_coef: 0.70 - ETA: 14s - loss: 0.1597 - dice_coef: 0.70 - ETA: 5s - loss: 0.1581 - dice_coef: 0.7083 - 324s 538ms/step - loss: 0.1583 - dice_coef: 0.7081 - val_loss: 0.1380 - val_dice_coef: 0.7463\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16856 to 0.13804, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - ETA: 4:56 - loss: 0.0996 - dice_coef: 0.780 - ETA: 4:49 - loss: 0.1213 - dice_coef: 0.760 - ETA: 4:41 - loss: 0.1338 - dice_coef: 0.759 - ETA: 4:33 - loss: 0.1361 - dice_coef: 0.761 - ETA: 4:24 - loss: 0.1287 - dice_coef: 0.757 - ETA: 4:17 - loss: 0.1359 - dice_coef: 0.754 - ETA: 4:08 - loss: 0.1331 - dice_coef: 0.750 - ETA: 4:00 - loss: 0.1291 - dice_coef: 0.752 - ETA: 3:52 - loss: 0.1259 - dice_coef: 0.751 - ETA: 3:44 - loss: 0.1266 - dice_coef: 0.753 - ETA: 3:36 - loss: 0.1301 - dice_coef: 0.748 - ETA: 3:28 - loss: 0.1303 - dice_coef: 0.752 - ETA: 3:20 - loss: 0.1312 - dice_coef: 0.752 - ETA: 3:11 - loss: 0.1298 - dice_coef: 0.753 - ETA: 3:03 - loss: 0.1326 - dice_coef: 0.755 - ETA: 2:55 - loss: 0.1309 - dice_coef: 0.757 - ETA: 2:47 - loss: 0.1306 - dice_coef: 0.757 - ETA: 2:39 - loss: 0.1299 - dice_coef: 0.757 - ETA: 2:31 - loss: 0.1296 - dice_coef: 0.759 - ETA: 2:23 - loss: 0.1308 - dice_coef: 0.760 - ETA: 2:15 - loss: 0.1332 - dice_coef: 0.760 - ETA: 2:07 - loss: 0.1319 - dice_coef: 0.760 - ETA: 1:59 - loss: 0.1326 - dice_coef: 0.760 - ETA: 1:50 - loss: 0.1309 - dice_coef: 0.759 - ETA: 1:42 - loss: 0.1328 - dice_coef: 0.758 - ETA: 1:34 - loss: 0.1333 - dice_coef: 0.758 - ETA: 1:26 - loss: 0.1331 - dice_coef: 0.758 - ETA: 1:18 - loss: 0.1333 - dice_coef: 0.754 - ETA: 1:10 - loss: 0.1333 - dice_coef: 0.755 - ETA: 1:02 - loss: 0.1326 - dice_coef: 0.755 - ETA: 54s - loss: 0.1319 - dice_coef: 0.756 - ETA: 46s - loss: 0.1304 - dice_coef: 0.75 - ETA: 38s - loss: 0.1310 - dice_coef: 0.75 - ETA: 29s - loss: 0.1306 - dice_coef: 0.75 - ETA: 21s - loss: 0.1289 - dice_coef: 0.75 - ETA: 13s - loss: 0.1282 - dice_coef: 0.75 - ETA: 5s - loss: 0.1291 - dice_coef: 0.7571 - 317s 526ms/step - loss: 0.1297 - dice_coef: 0.7567 - val_loss: 0.1263 - val_dice_coef: 0.7724\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.13804 to 0.12628, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 5/50\n",
      "603/603 [==============================] - ETA: 4:57 - loss: 0.0595 - dice_coef: 0.755 - ETA: 4:50 - loss: 0.0984 - dice_coef: 0.779 - ETA: 4:41 - loss: 0.1004 - dice_coef: 0.780 - ETA: 4:34 - loss: 0.1120 - dice_coef: 0.784 - ETA: 4:25 - loss: 0.1037 - dice_coef: 0.788 - ETA: 4:18 - loss: 0.1024 - dice_coef: 0.787 - ETA: 4:09 - loss: 0.1076 - dice_coef: 0.787 - ETA: 4:01 - loss: 0.1046 - dice_coef: 0.789 - ETA: 3:53 - loss: 0.1025 - dice_coef: 0.786 - ETA: 3:45 - loss: 0.1046 - dice_coef: 0.785 - ETA: 3:36 - loss: 0.1069 - dice_coef: 0.779 - ETA: 3:28 - loss: 0.1092 - dice_coef: 0.778 - ETA: 3:20 - loss: 0.1109 - dice_coef: 0.777 - ETA: 3:12 - loss: 0.1183 - dice_coef: 0.773 - ETA: 3:04 - loss: 0.1183 - dice_coef: 0.775 - ETA: 2:56 - loss: 0.1197 - dice_coef: 0.775 - ETA: 2:47 - loss: 0.1211 - dice_coef: 0.773 - ETA: 2:39 - loss: 0.1204 - dice_coef: 0.775 - ETA: 2:31 - loss: 0.1213 - dice_coef: 0.775 - ETA: 2:23 - loss: 0.1217 - dice_coef: 0.777 - ETA: 2:15 - loss: 0.1205 - dice_coef: 0.781 - ETA: 2:07 - loss: 0.1219 - dice_coef: 0.780 - ETA: 1:59 - loss: 0.1224 - dice_coef: 0.778 - ETA: 1:51 - loss: 0.1230 - dice_coef: 0.778 - ETA: 1:42 - loss: 0.1223 - dice_coef: 0.778 - ETA: 1:34 - loss: 0.1213 - dice_coef: 0.777 - ETA: 1:26 - loss: 0.1208 - dice_coef: 0.778 - ETA: 1:18 - loss: 0.1200 - dice_coef: 0.779 - ETA: 1:10 - loss: 0.1181 - dice_coef: 0.780 - ETA: 1:02 - loss: 0.1176 - dice_coef: 0.780 - ETA: 54s - loss: 0.1172 - dice_coef: 0.781 - ETA: 46s - loss: 0.1183 - dice_coef: 0.78 - ETA: 38s - loss: 0.1175 - dice_coef: 0.78 - ETA: 29s - loss: 0.1161 - dice_coef: 0.78 - ETA: 21s - loss: 0.1167 - dice_coef: 0.78 - ETA: 13s - loss: 0.1162 - dice_coef: 0.78 - ETA: 5s - loss: 0.1158 - dice_coef: 0.7843 - 317s 525ms/step - loss: 0.1154 - dice_coef: 0.7850 - val_loss: 0.1165 - val_dice_coef: 0.7995\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12628 to 0.11646, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 6/50\n",
      "603/603 [==============================] - ETA: 5:00 - loss: 0.0727 - dice_coef: 0.787 - ETA: 4:49 - loss: 0.1033 - dice_coef: 0.788 - ETA: 4:41 - loss: 0.1120 - dice_coef: 0.794 - ETA: 4:32 - loss: 0.1045 - dice_coef: 0.802 - ETA: 4:24 - loss: 0.0994 - dice_coef: 0.804 - ETA: 4:16 - loss: 0.0984 - dice_coef: 0.802 - ETA: 4:08 - loss: 0.1024 - dice_coef: 0.802 - ETA: 4:00 - loss: 0.0986 - dice_coef: 0.795 - ETA: 3:52 - loss: 0.0962 - dice_coef: 0.797 - ETA: 3:44 - loss: 0.0955 - dice_coef: 0.798 - ETA: 3:36 - loss: 0.0983 - dice_coef: 0.797 - ETA: 3:28 - loss: 0.0964 - dice_coef: 0.798 - ETA: 3:19 - loss: 0.0982 - dice_coef: 0.796 - ETA: 3:11 - loss: 0.0995 - dice_coef: 0.797 - ETA: 3:03 - loss: 0.1017 - dice_coef: 0.796 - ETA: 2:55 - loss: 0.1025 - dice_coef: 0.793 - ETA: 2:47 - loss: 0.1023 - dice_coef: 0.795 - ETA: 2:39 - loss: 0.1007 - dice_coef: 0.794 - ETA: 2:31 - loss: 0.1013 - dice_coef: 0.795 - ETA: 2:23 - loss: 0.1000 - dice_coef: 0.795 - ETA: 2:15 - loss: 0.1014 - dice_coef: 0.795 - ETA: 2:07 - loss: 0.1031 - dice_coef: 0.796 - ETA: 1:59 - loss: 0.1027 - dice_coef: 0.797 - ETA: 1:50 - loss: 0.1026 - dice_coef: 0.800 - ETA: 1:42 - loss: 0.1037 - dice_coef: 0.799 - ETA: 1:34 - loss: 0.1037 - dice_coef: 0.800 - ETA: 1:26 - loss: 0.1034 - dice_coef: 0.799 - ETA: 1:18 - loss: 0.1058 - dice_coef: 0.799 - ETA: 1:10 - loss: 0.1049 - dice_coef: 0.800 - ETA: 1:02 - loss: 0.1043 - dice_coef: 0.800 - ETA: 54s - loss: 0.1043 - dice_coef: 0.801 - ETA: 46s - loss: 0.1035 - dice_coef: 0.80 - ETA: 38s - loss: 0.1033 - dice_coef: 0.80 - ETA: 29s - loss: 0.1036 - dice_coef: 0.80 - ETA: 21s - loss: 0.1042 - dice_coef: 0.80 - ETA: 13s - loss: 0.1042 - dice_coef: 0.80 - ETA: 5s - loss: 0.1045 - dice_coef: 0.8049 - 317s 526ms/step - loss: 0.1053 - dice_coef: 0.8049 - val_loss: 0.1034 - val_dice_coef: 0.8075\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11646 to 0.10338, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 7/50\n",
      "603/603 [==============================] - ETA: 4:59 - loss: 0.1142 - dice_coef: 0.845 - ETA: 4:49 - loss: 0.1017 - dice_coef: 0.824 - ETA: 4:41 - loss: 0.1061 - dice_coef: 0.802 - ETA: 4:33 - loss: 0.0990 - dice_coef: 0.815 - ETA: 4:31 - loss: 0.1055 - dice_coef: 0.805 - ETA: 4:25 - loss: 0.0991 - dice_coef: 0.816 - ETA: 4:18 - loss: 0.0975 - dice_coef: 0.821 - ETA: 4:10 - loss: 0.0960 - dice_coef: 0.823 - ETA: 4:02 - loss: 0.0976 - dice_coef: 0.820 - ETA: 3:55 - loss: 0.0964 - dice_coef: 0.821 - ETA: 3:46 - loss: 0.0961 - dice_coef: 0.822 - ETA: 3:39 - loss: 0.0960 - dice_coef: 0.817 - ETA: 3:31 - loss: 0.1009 - dice_coef: 0.816 - ETA: 3:22 - loss: 0.0988 - dice_coef: 0.817 - ETA: 3:14 - loss: 0.0979 - dice_coef: 0.817 - ETA: 3:05 - loss: 0.0969 - dice_coef: 0.820 - ETA: 2:57 - loss: 0.0989 - dice_coef: 0.820 - ETA: 2:48 - loss: 0.0980 - dice_coef: 0.822 - ETA: 2:40 - loss: 0.0978 - dice_coef: 0.820 - ETA: 2:31 - loss: 0.0983 - dice_coef: 0.820 - ETA: 2:23 - loss: 0.0971 - dice_coef: 0.822 - ETA: 2:14 - loss: 0.0984 - dice_coef: 0.821 - ETA: 2:06 - loss: 0.0983 - dice_coef: 0.821 - ETA: 1:57 - loss: 0.1001 - dice_coef: 0.819 - ETA: 1:49 - loss: 0.1008 - dice_coef: 0.819 - ETA: 1:40 - loss: 0.1002 - dice_coef: 0.818 - ETA: 1:32 - loss: 0.1012 - dice_coef: 0.818 - ETA: 1:23 - loss: 0.1027 - dice_coef: 0.815 - ETA: 1:14 - loss: 0.1028 - dice_coef: 0.814 - ETA: 1:06 - loss: 0.1016 - dice_coef: 0.815 - ETA: 57s - loss: 0.1010 - dice_coef: 0.814 - ETA: 49s - loss: 0.1015 - dice_coef: 0.81 - ETA: 40s - loss: 0.1006 - dice_coef: 0.81 - ETA: 31s - loss: 0.0998 - dice_coef: 0.81 - ETA: 23s - loss: 0.0992 - dice_coef: 0.81 - ETA: 14s - loss: 0.0987 - dice_coef: 0.81 - ETA: 5s - loss: 0.0989 - dice_coef: 0.8140 - 338s 560ms/step - loss: 0.0994 - dice_coef: 0.8132 - val_loss: 0.1046 - val_dice_coef: 0.8154\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - ETA: 5:24 - loss: 0.0939 - dice_coef: 0.834 - ETA: 5:12 - loss: 0.0890 - dice_coef: 0.845 - ETA: 5:05 - loss: 0.0760 - dice_coef: 0.855 - ETA: 4:55 - loss: 0.0803 - dice_coef: 0.848 - ETA: 4:46 - loss: 0.0859 - dice_coef: 0.840 - ETA: 4:38 - loss: 0.0882 - dice_coef: 0.835 - ETA: 4:28 - loss: 0.0904 - dice_coef: 0.838 - ETA: 4:19 - loss: 0.0956 - dice_coef: 0.835 - ETA: 4:10 - loss: 0.0922 - dice_coef: 0.838 - ETA: 4:01 - loss: 0.0946 - dice_coef: 0.837 - ETA: 3:52 - loss: 0.0951 - dice_coef: 0.836 - ETA: 3:44 - loss: 0.0933 - dice_coef: 0.837 - ETA: 3:35 - loss: 0.0939 - dice_coef: 0.837 - ETA: 3:26 - loss: 0.0921 - dice_coef: 0.838 - ETA: 3:18 - loss: 0.0920 - dice_coef: 0.837 - ETA: 3:09 - loss: 0.0903 - dice_coef: 0.835 - ETA: 3:00 - loss: 0.0900 - dice_coef: 0.835 - ETA: 2:51 - loss: 0.0901 - dice_coef: 0.835 - ETA: 2:43 - loss: 0.0907 - dice_coef: 0.833 - ETA: 2:34 - loss: 0.0925 - dice_coef: 0.832 - ETA: 2:25 - loss: 0.0913 - dice_coef: 0.831 - ETA: 2:16 - loss: 0.0917 - dice_coef: 0.830 - ETA: 2:08 - loss: 0.0908 - dice_coef: 0.832 - ETA: 1:59 - loss: 0.0897 - dice_coef: 0.831 - ETA: 1:50 - loss: 0.0896 - dice_coef: 0.829 - ETA: 1:42 - loss: 0.0897 - dice_coef: 0.830 - ETA: 1:33 - loss: 0.0903 - dice_coef: 0.830 - ETA: 1:24 - loss: 0.0899 - dice_coef: 0.831 - ETA: 1:15 - loss: 0.0898 - dice_coef: 0.831 - ETA: 1:07 - loss: 0.0903 - dice_coef: 0.831 - ETA: 58s - loss: 0.0902 - dice_coef: 0.832 - ETA: 49s - loss: 0.0907 - dice_coef: 0.83 - ETA: 40s - loss: 0.0899 - dice_coef: 0.83 - ETA: 32s - loss: 0.0927 - dice_coef: 0.82 - ETA: 23s - loss: 0.0916 - dice_coef: 0.83 - ETA: 14s - loss: 0.0924 - dice_coef: 0.83 - ETA: 5s - loss: 0.0937 - dice_coef: 0.8288 - 338s 561ms/step - loss: 0.0933 - dice_coef: 0.8298 - val_loss: 0.1039 - val_dice_coef: 0.8190\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/50\n",
      "603/603 [==============================] - ETA: 5:07 - loss: 0.0545 - dice_coef: 0.832 - ETA: 5:19 - loss: 0.0680 - dice_coef: 0.831 - ETA: 5:05 - loss: 0.0617 - dice_coef: 0.840 - ETA: 4:57 - loss: 0.0623 - dice_coef: 0.837 - ETA: 4:49 - loss: 0.0650 - dice_coef: 0.844 - ETA: 4:40 - loss: 0.0683 - dice_coef: 0.843 - ETA: 4:32 - loss: 0.0718 - dice_coef: 0.844 - ETA: 4:26 - loss: 0.0755 - dice_coef: 0.839 - ETA: 4:18 - loss: 0.0762 - dice_coef: 0.836 - ETA: 4:09 - loss: 0.0759 - dice_coef: 0.836 - ETA: 4:00 - loss: 0.0758 - dice_coef: 0.835 - ETA: 3:50 - loss: 0.0748 - dice_coef: 0.836 - ETA: 3:41 - loss: 0.0759 - dice_coef: 0.837 - ETA: 3:31 - loss: 0.0794 - dice_coef: 0.835 - ETA: 3:21 - loss: 0.0835 - dice_coef: 0.831 - ETA: 3:12 - loss: 0.0874 - dice_coef: 0.829 - ETA: 3:02 - loss: 0.0901 - dice_coef: 0.829 - ETA: 2:53 - loss: 0.0896 - dice_coef: 0.829 - ETA: 2:44 - loss: 0.0901 - dice_coef: 0.829 - ETA: 2:35 - loss: 0.0894 - dice_coef: 0.827 - ETA: 2:25 - loss: 0.0909 - dice_coef: 0.825 - ETA: 2:16 - loss: 0.0913 - dice_coef: 0.826 - ETA: 2:07 - loss: 0.0907 - dice_coef: 0.828 - ETA: 1:59 - loss: 0.0913 - dice_coef: 0.828 - ETA: 1:50 - loss: 0.0913 - dice_coef: 0.826 - ETA: 1:41 - loss: 0.0916 - dice_coef: 0.827 - ETA: 1:32 - loss: 0.0924 - dice_coef: 0.826 - ETA: 1:23 - loss: 0.0936 - dice_coef: 0.827 - ETA: 1:15 - loss: 0.0950 - dice_coef: 0.827 - ETA: 1:06 - loss: 0.0952 - dice_coef: 0.826 - ETA: 57s - loss: 0.0953 - dice_coef: 0.826 - ETA: 49s - loss: 0.0968 - dice_coef: 0.82 - ETA: 40s - loss: 0.0967 - dice_coef: 0.82 - ETA: 31s - loss: 0.0963 - dice_coef: 0.82 - ETA: 23s - loss: 0.0961 - dice_coef: 0.82 - ETA: 14s - loss: 0.0966 - dice_coef: 0.82 - ETA: 5s - loss: 0.0962 - dice_coef: 0.8258 - 336s 557ms/step - loss: 0.0966 - dice_coef: 0.8255 - val_loss: 0.0952 - val_dice_coef: 0.8087\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10338 to 0.09517, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 10/50\n",
      "603/603 [==============================] - ETA: 5:12 - loss: 0.0966 - dice_coef: 0.836 - ETA: 5:08 - loss: 0.1060 - dice_coef: 0.797 - ETA: 4:58 - loss: 0.1007 - dice_coef: 0.797 - ETA: 4:48 - loss: 0.0944 - dice_coef: 0.799 - ETA: 4:39 - loss: 0.0940 - dice_coef: 0.802 - ETA: 4:30 - loss: 0.0931 - dice_coef: 0.805 - ETA: 4:21 - loss: 0.0951 - dice_coef: 0.801 - ETA: 4:12 - loss: 0.0992 - dice_coef: 0.802 - ETA: 4:03 - loss: 0.0956 - dice_coef: 0.803 - ETA: 3:54 - loss: 0.0991 - dice_coef: 0.801 - ETA: 3:45 - loss: 0.0996 - dice_coef: 0.801 - ETA: 3:37 - loss: 0.0984 - dice_coef: 0.804 - ETA: 3:28 - loss: 0.1011 - dice_coef: 0.807 - ETA: 3:20 - loss: 0.0996 - dice_coef: 0.810 - ETA: 3:11 - loss: 0.0992 - dice_coef: 0.811 - ETA: 3:03 - loss: 0.1020 - dice_coef: 0.811 - ETA: 2:54 - loss: 0.1024 - dice_coef: 0.811 - ETA: 2:46 - loss: 0.1001 - dice_coef: 0.813 - ETA: 2:37 - loss: 0.0982 - dice_coef: 0.815 - ETA: 2:30 - loss: 0.0990 - dice_coef: 0.814 - ETA: 2:21 - loss: 0.0982 - dice_coef: 0.813 - ETA: 2:12 - loss: 0.0970 - dice_coef: 0.815 - ETA: 2:04 - loss: 0.0968 - dice_coef: 0.815 - ETA: 1:55 - loss: 0.0969 - dice_coef: 0.814 - ETA: 1:47 - loss: 0.0965 - dice_coef: 0.816 - ETA: 1:38 - loss: 0.0960 - dice_coef: 0.816 - ETA: 1:30 - loss: 0.0960 - dice_coef: 0.818 - ETA: 1:21 - loss: 0.0952 - dice_coef: 0.820 - ETA: 1:13 - loss: 0.0943 - dice_coef: 0.821 - ETA: 1:04 - loss: 0.0932 - dice_coef: 0.823 - ETA: 56s - loss: 0.0945 - dice_coef: 0.822 - ETA: 48s - loss: 0.0935 - dice_coef: 0.82 - ETA: 39s - loss: 0.0928 - dice_coef: 0.82 - ETA: 31s - loss: 0.0928 - dice_coef: 0.82 - ETA: 22s - loss: 0.0927 - dice_coef: 0.82 - ETA: 14s - loss: 0.0923 - dice_coef: 0.82 - ETA: 5s - loss: 0.0916 - dice_coef: 0.8245 - 329s 546ms/step - loss: 0.0910 - dice_coef: 0.8259 - val_loss: 0.0889 - val_dice_coef: 0.8378\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09517 to 0.08892, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 11/50\n",
      "603/603 [==============================] - ETA: 5:00 - loss: 0.0782 - dice_coef: 0.814 - ETA: 4:54 - loss: 0.0689 - dice_coef: 0.842 - ETA: 4:51 - loss: 0.0609 - dice_coef: 0.861 - ETA: 4:40 - loss: 0.0753 - dice_coef: 0.850 - ETA: 4:31 - loss: 0.0740 - dice_coef: 0.856 - ETA: 4:22 - loss: 0.0793 - dice_coef: 0.852 - ETA: 4:15 - loss: 0.0829 - dice_coef: 0.852 - ETA: 4:09 - loss: 0.0830 - dice_coef: 0.850 - ETA: 4:01 - loss: 0.0814 - dice_coef: 0.853 - ETA: 3:53 - loss: 0.0889 - dice_coef: 0.850 - ETA: 3:44 - loss: 0.0890 - dice_coef: 0.850 - ETA: 3:35 - loss: 0.0875 - dice_coef: 0.852 - ETA: 3:27 - loss: 0.0886 - dice_coef: 0.849 - ETA: 3:18 - loss: 0.0866 - dice_coef: 0.850 - ETA: 3:10 - loss: 0.0860 - dice_coef: 0.849 - ETA: 3:01 - loss: 0.0842 - dice_coef: 0.847 - ETA: 2:53 - loss: 0.0847 - dice_coef: 0.847 - ETA: 2:45 - loss: 0.0859 - dice_coef: 0.846 - ETA: 2:37 - loss: 0.0854 - dice_coef: 0.846 - ETA: 2:28 - loss: 0.0850 - dice_coef: 0.847 - ETA: 2:20 - loss: 0.0836 - dice_coef: 0.848 - ETA: 2:11 - loss: 0.0835 - dice_coef: 0.849 - ETA: 2:03 - loss: 0.0846 - dice_coef: 0.849 - ETA: 1:55 - loss: 0.0851 - dice_coef: 0.848 - ETA: 1:46 - loss: 0.0856 - dice_coef: 0.848 - ETA: 1:38 - loss: 0.0852 - dice_coef: 0.848 - ETA: 1:29 - loss: 0.0850 - dice_coef: 0.848 - ETA: 1:21 - loss: 0.0850 - dice_coef: 0.848 - ETA: 1:12 - loss: 0.0856 - dice_coef: 0.847 - ETA: 1:04 - loss: 0.0861 - dice_coef: 0.846 - ETA: 56s - loss: 0.0859 - dice_coef: 0.845 - ETA: 48s - loss: 0.0849 - dice_coef: 0.84 - ETA: 39s - loss: 0.0848 - dice_coef: 0.84 - ETA: 31s - loss: 0.0843 - dice_coef: 0.84 - ETA: 22s - loss: 0.0842 - dice_coef: 0.84 - ETA: 14s - loss: 0.0847 - dice_coef: 0.84 - ETA: 5s - loss: 0.0861 - dice_coef: 0.8435 - 334s 553ms/step - loss: 0.0862 - dice_coef: 0.8431 - val_loss: 0.0907 - val_dice_coef: 0.8337\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - ETA: 5:20 - loss: 0.0711 - dice_coef: 0.871 - ETA: 5:08 - loss: 0.0780 - dice_coef: 0.868 - ETA: 5:01 - loss: 0.0827 - dice_coef: 0.856 - ETA: 5:00 - loss: 0.0838 - dice_coef: 0.852 - ETA: 4:51 - loss: 0.0889 - dice_coef: 0.835 - ETA: 4:42 - loss: 0.0914 - dice_coef: 0.830 - ETA: 4:32 - loss: 0.0894 - dice_coef: 0.831 - ETA: 4:22 - loss: 0.0847 - dice_coef: 0.835 - ETA: 4:11 - loss: 0.0823 - dice_coef: 0.831 - ETA: 4:01 - loss: 0.0816 - dice_coef: 0.833 - ETA: 3:52 - loss: 0.0810 - dice_coef: 0.834 - ETA: 3:45 - loss: 0.0823 - dice_coef: 0.836 - ETA: 3:35 - loss: 0.0873 - dice_coef: 0.837 - ETA: 3:26 - loss: 0.0882 - dice_coef: 0.836 - ETA: 3:17 - loss: 0.0905 - dice_coef: 0.837 - ETA: 3:08 - loss: 0.0933 - dice_coef: 0.831 - ETA: 2:59 - loss: 0.0950 - dice_coef: 0.829 - ETA: 2:51 - loss: 0.0935 - dice_coef: 0.828 - ETA: 2:41 - loss: 0.0946 - dice_coef: 0.827 - ETA: 2:33 - loss: 0.0958 - dice_coef: 0.827 - ETA: 2:24 - loss: 0.0950 - dice_coef: 0.828 - ETA: 2:16 - loss: 0.0939 - dice_coef: 0.829 - ETA: 2:07 - loss: 0.0931 - dice_coef: 0.831 - ETA: 1:59 - loss: 0.0930 - dice_coef: 0.831 - ETA: 1:50 - loss: 0.0908 - dice_coef: 0.829 - ETA: 1:42 - loss: 0.0912 - dice_coef: 0.827 - ETA: 1:33 - loss: 0.0912 - dice_coef: 0.827 - ETA: 1:25 - loss: 0.0907 - dice_coef: 0.828 - ETA: 1:16 - loss: 0.0903 - dice_coef: 0.828 - ETA: 1:07 - loss: 0.0897 - dice_coef: 0.829 - ETA: 58s - loss: 0.0895 - dice_coef: 0.830 - ETA: 50s - loss: 0.0891 - dice_coef: 0.83 - ETA: 41s - loss: 0.0880 - dice_coef: 0.82 - ETA: 32s - loss: 0.0872 - dice_coef: 0.83 - ETA: 23s - loss: 0.0877 - dice_coef: 0.83 - ETA: 14s - loss: 0.0867 - dice_coef: 0.83 - ETA: 6s - loss: 0.0857 - dice_coef: 0.8333 - 343s 569ms/step - loss: 0.0858 - dice_coef: 0.8343 - val_loss: 0.0912 - val_dice_coef: 0.8436\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/50\n",
      "603/603 [==============================] - ETA: 5:17 - loss: 0.0859 - dice_coef: 0.870 - ETA: 5:05 - loss: 0.0744 - dice_coef: 0.874 - ETA: 4:57 - loss: 0.0720 - dice_coef: 0.878 - ETA: 4:49 - loss: 0.0686 - dice_coef: 0.872 - ETA: 4:39 - loss: 0.0692 - dice_coef: 0.872 - ETA: 4:30 - loss: 0.0682 - dice_coef: 0.870 - ETA: 4:20 - loss: 0.0704 - dice_coef: 0.868 - ETA: 4:12 - loss: 0.0701 - dice_coef: 0.869 - ETA: 4:03 - loss: 0.0740 - dice_coef: 0.865 - ETA: 3:55 - loss: 0.0807 - dice_coef: 0.865 - ETA: 3:46 - loss: 0.0781 - dice_coef: 0.866 - ETA: 3:38 - loss: 0.0801 - dice_coef: 0.863 - ETA: 3:29 - loss: 0.0794 - dice_coef: 0.860 - ETA: 3:20 - loss: 0.0819 - dice_coef: 0.855 - ETA: 3:12 - loss: 0.0819 - dice_coef: 0.853 - ETA: 3:03 - loss: 0.0810 - dice_coef: 0.854 - ETA: 2:54 - loss: 0.0830 - dice_coef: 0.852 - ETA: 2:46 - loss: 0.0816 - dice_coef: 0.851 - ETA: 2:38 - loss: 0.0819 - dice_coef: 0.851 - ETA: 2:29 - loss: 0.0863 - dice_coef: 0.847 - ETA: 2:21 - loss: 0.0873 - dice_coef: 0.846 - ETA: 2:12 - loss: 0.0891 - dice_coef: 0.845 - ETA: 2:04 - loss: 0.0887 - dice_coef: 0.845 - ETA: 1:55 - loss: 0.0884 - dice_coef: 0.844 - ETA: 1:47 - loss: 0.0880 - dice_coef: 0.845 - ETA: 1:39 - loss: 0.0875 - dice_coef: 0.845 - ETA: 1:31 - loss: 0.0874 - dice_coef: 0.843 - ETA: 1:22 - loss: 0.0869 - dice_coef: 0.844 - ETA: 1:14 - loss: 0.0865 - dice_coef: 0.843 - ETA: 1:05 - loss: 0.0860 - dice_coef: 0.842 - ETA: 57s - loss: 0.0849 - dice_coef: 0.843 - ETA: 48s - loss: 0.0848 - dice_coef: 0.84 - ETA: 40s - loss: 0.0842 - dice_coef: 0.84 - ETA: 31s - loss: 0.0854 - dice_coef: 0.84 - ETA: 22s - loss: 0.0845 - dice_coef: 0.84 - ETA: 14s - loss: 0.0836 - dice_coef: 0.84 - ETA: 5s - loss: 0.0830 - dice_coef: 0.8465 - 333s 552ms/step - loss: 0.0824 - dice_coef: 0.8473 - val_loss: 0.0891 - val_dice_coef: 0.8435\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/50\n",
      "603/603 [==============================] - ETA: 5:11 - loss: 0.1231 - dice_coef: 0.807 - ETA: 5:00 - loss: 0.1101 - dice_coef: 0.839 - ETA: 4:53 - loss: 0.1046 - dice_coef: 0.839 - ETA: 4:43 - loss: 0.1028 - dice_coef: 0.838 - ETA: 4:35 - loss: 0.1050 - dice_coef: 0.838 - ETA: 4:25 - loss: 0.1011 - dice_coef: 0.841 - ETA: 4:16 - loss: 0.0993 - dice_coef: 0.848 - ETA: 4:07 - loss: 0.0943 - dice_coef: 0.850 - ETA: 3:58 - loss: 0.0937 - dice_coef: 0.845 - ETA: 3:49 - loss: 0.0903 - dice_coef: 0.847 - ETA: 3:40 - loss: 0.0901 - dice_coef: 0.848 - ETA: 3:32 - loss: 0.0885 - dice_coef: 0.849 - ETA: 3:23 - loss: 0.0863 - dice_coef: 0.846 - ETA: 3:15 - loss: 0.0843 - dice_coef: 0.847 - ETA: 3:07 - loss: 0.0824 - dice_coef: 0.849 - ETA: 2:58 - loss: 0.0819 - dice_coef: 0.849 - ETA: 2:50 - loss: 0.0832 - dice_coef: 0.848 - ETA: 2:41 - loss: 0.0829 - dice_coef: 0.844 - ETA: 2:34 - loss: 0.0825 - dice_coef: 0.845 - ETA: 2:26 - loss: 0.0821 - dice_coef: 0.846 - ETA: 2:18 - loss: 0.0813 - dice_coef: 0.848 - ETA: 2:10 - loss: 0.0803 - dice_coef: 0.850 - ETA: 2:02 - loss: 0.0797 - dice_coef: 0.850 - ETA: 1:54 - loss: 0.0790 - dice_coef: 0.852 - ETA: 1:46 - loss: 0.0793 - dice_coef: 0.851 - ETA: 1:38 - loss: 0.0789 - dice_coef: 0.852 - ETA: 1:29 - loss: 0.0791 - dice_coef: 0.852 - ETA: 1:21 - loss: 0.0808 - dice_coef: 0.852 - ETA: 1:13 - loss: 0.0810 - dice_coef: 0.852 - ETA: 1:04 - loss: 0.0809 - dice_coef: 0.852 - ETA: 56s - loss: 0.0814 - dice_coef: 0.851 - ETA: 47s - loss: 0.0812 - dice_coef: 0.85 - ETA: 39s - loss: 0.0806 - dice_coef: 0.85 - ETA: 31s - loss: 0.0810 - dice_coef: 0.85 - ETA: 22s - loss: 0.0801 - dice_coef: 0.85 - ETA: 14s - loss: 0.0794 - dice_coef: 0.85 - ETA: 5s - loss: 0.0801 - dice_coef: 0.8504 - 328s 545ms/step - loss: 0.0813 - dice_coef: 0.8492 - val_loss: 0.0890 - val_dice_coef: 0.8340\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/50\n",
      "603/603 [==============================] - ETA: 5:05 - loss: 0.0516 - dice_coef: 0.887 - ETA: 5:05 - loss: 0.0777 - dice_coef: 0.844 - ETA: 4:54 - loss: 0.0708 - dice_coef: 0.853 - ETA: 4:45 - loss: 0.0790 - dice_coef: 0.843 - ETA: 4:36 - loss: 0.0875 - dice_coef: 0.835 - ETA: 4:27 - loss: 0.0858 - dice_coef: 0.838 - ETA: 4:19 - loss: 0.0880 - dice_coef: 0.837 - ETA: 4:11 - loss: 0.0917 - dice_coef: 0.833 - ETA: 4:02 - loss: 0.0895 - dice_coef: 0.831 - ETA: 3:53 - loss: 0.0873 - dice_coef: 0.833 - ETA: 3:45 - loss: 0.0838 - dice_coef: 0.836 - ETA: 3:36 - loss: 0.0850 - dice_coef: 0.837 - ETA: 3:28 - loss: 0.0829 - dice_coef: 0.839 - ETA: 3:20 - loss: 0.0835 - dice_coef: 0.840 - ETA: 3:12 - loss: 0.0826 - dice_coef: 0.842 - ETA: 3:03 - loss: 0.0819 - dice_coef: 0.846 - ETA: 2:55 - loss: 0.0814 - dice_coef: 0.847 - ETA: 2:46 - loss: 0.0818 - dice_coef: 0.848 - ETA: 2:38 - loss: 0.0805 - dice_coef: 0.848 - ETA: 2:30 - loss: 0.0818 - dice_coef: 0.849 - ETA: 2:22 - loss: 0.0823 - dice_coef: 0.849 - ETA: 2:15 - loss: 0.0818 - dice_coef: 0.848 - ETA: 2:06 - loss: 0.0833 - dice_coef: 0.845 - ETA: 1:57 - loss: 0.0833 - dice_coef: 0.845 - ETA: 1:48 - loss: 0.0830 - dice_coef: 0.846 - ETA: 1:40 - loss: 0.0834 - dice_coef: 0.846 - ETA: 1:31 - loss: 0.0824 - dice_coef: 0.847 - ETA: 1:23 - loss: 0.0818 - dice_coef: 0.846 - ETA: 1:14 - loss: 0.0821 - dice_coef: 0.844 - ETA: 1:06 - loss: 0.0828 - dice_coef: 0.841 - ETA: 57s - loss: 0.0827 - dice_coef: 0.840 - ETA: 48s - loss: 0.0825 - dice_coef: 0.84 - ETA: 40s - loss: 0.0828 - dice_coef: 0.83 - ETA: 31s - loss: 0.0828 - dice_coef: 0.84 - ETA: 23s - loss: 0.0829 - dice_coef: 0.84 - ETA: 14s - loss: 0.0840 - dice_coef: 0.84 - ETA: 5s - loss: 0.0846 - dice_coef: 0.8404 - 337s 559ms/step - loss: 0.0853 - dice_coef: 0.8409 - val_loss: 0.0867 - val_dice_coef: 0.8403\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08892 to 0.08668, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - ETA: 5:11 - loss: 0.0684 - dice_coef: 0.863 - ETA: 5:04 - loss: 0.0700 - dice_coef: 0.859 - ETA: 4:54 - loss: 0.0721 - dice_coef: 0.856 - ETA: 4:45 - loss: 0.0762 - dice_coef: 0.851 - ETA: 4:36 - loss: 0.0761 - dice_coef: 0.850 - ETA: 4:28 - loss: 0.0756 - dice_coef: 0.841 - ETA: 4:19 - loss: 0.0761 - dice_coef: 0.844 - ETA: 4:10 - loss: 0.0816 - dice_coef: 0.841 - ETA: 4:02 - loss: 0.0809 - dice_coef: 0.842 - ETA: 3:53 - loss: 0.0799 - dice_coef: 0.841 - ETA: 3:45 - loss: 0.0793 - dice_coef: 0.842 - ETA: 3:36 - loss: 0.0801 - dice_coef: 0.842 - ETA: 3:28 - loss: 0.0802 - dice_coef: 0.843 - ETA: 3:19 - loss: 0.0808 - dice_coef: 0.842 - ETA: 3:11 - loss: 0.0811 - dice_coef: 0.841 - ETA: 3:02 - loss: 0.0829 - dice_coef: 0.840 - ETA: 2:54 - loss: 0.0823 - dice_coef: 0.837 - ETA: 2:46 - loss: 0.0833 - dice_coef: 0.837 - ETA: 2:37 - loss: 0.0821 - dice_coef: 0.839 - ETA: 2:29 - loss: 0.0816 - dice_coef: 0.841 - ETA: 2:20 - loss: 0.0813 - dice_coef: 0.842 - ETA: 2:12 - loss: 0.0812 - dice_coef: 0.843 - ETA: 2:03 - loss: 0.0821 - dice_coef: 0.844 - ETA: 1:55 - loss: 0.0812 - dice_coef: 0.846 - ETA: 1:47 - loss: 0.0807 - dice_coef: 0.847 - ETA: 1:38 - loss: 0.0796 - dice_coef: 0.849 - ETA: 1:30 - loss: 0.0796 - dice_coef: 0.849 - ETA: 1:21 - loss: 0.0808 - dice_coef: 0.848 - ETA: 1:13 - loss: 0.0815 - dice_coef: 0.847 - ETA: 1:05 - loss: 0.0810 - dice_coef: 0.848 - ETA: 56s - loss: 0.0808 - dice_coef: 0.849 - ETA: 48s - loss: 0.0811 - dice_coef: 0.84 - ETA: 39s - loss: 0.0806 - dice_coef: 0.84 - ETA: 31s - loss: 0.0801 - dice_coef: 0.84 - ETA: 22s - loss: 0.0804 - dice_coef: 0.84 - ETA: 14s - loss: 0.0801 - dice_coef: 0.84 - ETA: 5s - loss: 0.0793 - dice_coef: 0.8500 - 333s 553ms/step - loss: 0.0792 - dice_coef: 0.8501 - val_loss: 0.0786 - val_dice_coef: 0.8448\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08668 to 0.07856, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 17/50\n",
      "603/603 [==============================] - ETA: 5:06 - loss: 0.0520 - dice_coef: 0.888 - ETA: 5:00 - loss: 0.0762 - dice_coef: 0.859 - ETA: 4:51 - loss: 0.0745 - dice_coef: 0.870 - ETA: 4:43 - loss: 0.0659 - dice_coef: 0.879 - ETA: 4:35 - loss: 0.0636 - dice_coef: 0.881 - ETA: 4:27 - loss: 0.0622 - dice_coef: 0.878 - ETA: 4:18 - loss: 0.0644 - dice_coef: 0.877 - ETA: 4:10 - loss: 0.0662 - dice_coef: 0.874 - ETA: 4:01 - loss: 0.0735 - dice_coef: 0.870 - ETA: 3:53 - loss: 0.0715 - dice_coef: 0.870 - ETA: 3:44 - loss: 0.0743 - dice_coef: 0.869 - ETA: 3:36 - loss: 0.0734 - dice_coef: 0.870 - ETA: 3:27 - loss: 0.0733 - dice_coef: 0.869 - ETA: 3:19 - loss: 0.0728 - dice_coef: 0.866 - ETA: 3:11 - loss: 0.0726 - dice_coef: 0.865 - ETA: 3:03 - loss: 0.0744 - dice_coef: 0.864 - ETA: 2:55 - loss: 0.0738 - dice_coef: 0.863 - ETA: 2:46 - loss: 0.0757 - dice_coef: 0.860 - ETA: 2:38 - loss: 0.0761 - dice_coef: 0.859 - ETA: 2:29 - loss: 0.0764 - dice_coef: 0.858 - ETA: 2:21 - loss: 0.0786 - dice_coef: 0.853 - ETA: 2:12 - loss: 0.0795 - dice_coef: 0.852 - ETA: 2:04 - loss: 0.0797 - dice_coef: 0.851 - ETA: 1:55 - loss: 0.0794 - dice_coef: 0.851 - ETA: 1:47 - loss: 0.0778 - dice_coef: 0.853 - ETA: 1:38 - loss: 0.0774 - dice_coef: 0.853 - ETA: 1:30 - loss: 0.0765 - dice_coef: 0.854 - ETA: 1:21 - loss: 0.0766 - dice_coef: 0.854 - ETA: 1:13 - loss: 0.0765 - dice_coef: 0.854 - ETA: 1:04 - loss: 0.0764 - dice_coef: 0.854 - ETA: 56s - loss: 0.0769 - dice_coef: 0.853 - ETA: 48s - loss: 0.0777 - dice_coef: 0.85 - ETA: 39s - loss: 0.0773 - dice_coef: 0.85 - ETA: 31s - loss: 0.0759 - dice_coef: 0.85 - ETA: 22s - loss: 0.0764 - dice_coef: 0.85 - ETA: 14s - loss: 0.0766 - dice_coef: 0.85 - ETA: 5s - loss: 0.0763 - dice_coef: 0.8561 - 330s 547ms/step - loss: 0.0769 - dice_coef: 0.8558 - val_loss: 0.0829 - val_dice_coef: 0.8472\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/50\n",
      "603/603 [==============================] - ETA: 5:11 - loss: 0.0946 - dice_coef: 0.854 - ETA: 5:00 - loss: 0.0745 - dice_coef: 0.854 - ETA: 4:53 - loss: 0.0688 - dice_coef: 0.852 - ETA: 4:43 - loss: 0.0643 - dice_coef: 0.857 - ETA: 4:35 - loss: 0.0605 - dice_coef: 0.865 - ETA: 4:26 - loss: 0.0649 - dice_coef: 0.866 - ETA: 4:18 - loss: 0.0660 - dice_coef: 0.863 - ETA: 4:11 - loss: 0.0677 - dice_coef: 0.862 - ETA: 4:03 - loss: 0.0711 - dice_coef: 0.862 - ETA: 3:54 - loss: 0.0707 - dice_coef: 0.863 - ETA: 3:46 - loss: 0.0694 - dice_coef: 0.861 - ETA: 3:38 - loss: 0.0694 - dice_coef: 0.860 - ETA: 3:29 - loss: 0.0681 - dice_coef: 0.860 - ETA: 3:22 - loss: 0.0675 - dice_coef: 0.861 - ETA: 3:13 - loss: 0.0689 - dice_coef: 0.862 - ETA: 3:05 - loss: 0.0692 - dice_coef: 0.862 - ETA: 2:57 - loss: 0.0696 - dice_coef: 0.863 - ETA: 2:48 - loss: 0.0689 - dice_coef: 0.863 - ETA: 2:39 - loss: 0.0702 - dice_coef: 0.861 - ETA: 2:30 - loss: 0.0710 - dice_coef: 0.860 - ETA: 2:21 - loss: 0.0707 - dice_coef: 0.862 - ETA: 2:13 - loss: 0.0710 - dice_coef: 0.862 - ETA: 2:04 - loss: 0.0723 - dice_coef: 0.862 - ETA: 1:55 - loss: 0.0724 - dice_coef: 0.863 - ETA: 1:47 - loss: 0.0729 - dice_coef: 0.861 - ETA: 1:38 - loss: 0.0729 - dice_coef: 0.860 - ETA: 1:29 - loss: 0.0735 - dice_coef: 0.859 - ETA: 1:21 - loss: 0.0736 - dice_coef: 0.859 - ETA: 1:13 - loss: 0.0732 - dice_coef: 0.861 - ETA: 1:04 - loss: 0.0735 - dice_coef: 0.860 - ETA: 56s - loss: 0.0756 - dice_coef: 0.857 - ETA: 47s - loss: 0.0757 - dice_coef: 0.85 - ETA: 39s - loss: 0.0750 - dice_coef: 0.85 - ETA: 30s - loss: 0.0762 - dice_coef: 0.85 - ETA: 22s - loss: 0.0764 - dice_coef: 0.85 - ETA: 14s - loss: 0.0765 - dice_coef: 0.85 - ETA: 5s - loss: 0.0758 - dice_coef: 0.8563 - 329s 545ms/step - loss: 0.0759 - dice_coef: 0.8561 - val_loss: 0.0820 - val_dice_coef: 0.8419\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/50\n",
      "603/603 [==============================] - ETA: 4:53 - loss: 0.0715 - dice_coef: 0.883 - ETA: 4:49 - loss: 0.0585 - dice_coef: 0.883 - ETA: 4:44 - loss: 0.0654 - dice_coef: 0.878 - ETA: 4:38 - loss: 0.0633 - dice_coef: 0.873 - ETA: 4:30 - loss: 0.0665 - dice_coef: 0.870 - ETA: 4:23 - loss: 0.0696 - dice_coef: 0.869 - ETA: 4:14 - loss: 0.0681 - dice_coef: 0.870 - ETA: 4:06 - loss: 0.0695 - dice_coef: 0.866 - ETA: 3:56 - loss: 0.0697 - dice_coef: 0.867 - ETA: 3:48 - loss: 0.0721 - dice_coef: 0.869 - ETA: 3:39 - loss: 0.0718 - dice_coef: 0.868 - ETA: 3:32 - loss: 0.0729 - dice_coef: 0.867 - ETA: 3:23 - loss: 0.0732 - dice_coef: 0.868 - ETA: 3:14 - loss: 0.0749 - dice_coef: 0.864 - ETA: 3:06 - loss: 0.0734 - dice_coef: 0.865 - ETA: 2:58 - loss: 0.0738 - dice_coef: 0.864 - ETA: 2:50 - loss: 0.0743 - dice_coef: 0.864 - ETA: 2:41 - loss: 0.0738 - dice_coef: 0.863 - ETA: 2:33 - loss: 0.0755 - dice_coef: 0.859 - ETA: 2:26 - loss: 0.0755 - dice_coef: 0.858 - ETA: 2:18 - loss: 0.0756 - dice_coef: 0.857 - ETA: 2:10 - loss: 0.0754 - dice_coef: 0.856 - ETA: 2:02 - loss: 0.0754 - dice_coef: 0.854 - ETA: 1:53 - loss: 0.0756 - dice_coef: 0.853 - ETA: 1:45 - loss: 0.0754 - dice_coef: 0.854 - ETA: 1:37 - loss: 0.0747 - dice_coef: 0.854 - ETA: 1:29 - loss: 0.0752 - dice_coef: 0.853 - ETA: 1:20 - loss: 0.0758 - dice_coef: 0.853 - ETA: 1:12 - loss: 0.0766 - dice_coef: 0.853 - ETA: 1:04 - loss: 0.0761 - dice_coef: 0.854 - ETA: 56s - loss: 0.0762 - dice_coef: 0.853 - ETA: 47s - loss: 0.0761 - dice_coef: 0.85 - ETA: 39s - loss: 0.0758 - dice_coef: 0.85 - ETA: 31s - loss: 0.0759 - dice_coef: 0.85 - ETA: 22s - loss: 0.0763 - dice_coef: 0.85 - ETA: 14s - loss: 0.0763 - dice_coef: 0.85 - ETA: 5s - loss: 0.0759 - dice_coef: 0.8557 - 329s 546ms/step - loss: 0.0759 - dice_coef: 0.8560 - val_loss: 0.0863 - val_dice_coef: 0.8452\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - ETA: 5:02 - loss: 0.0752 - dice_coef: 0.816 - ETA: 4:50 - loss: 0.0664 - dice_coef: 0.854 - ETA: 4:43 - loss: 0.0709 - dice_coef: 0.857 - ETA: 4:34 - loss: 0.0697 - dice_coef: 0.854 - ETA: 4:26 - loss: 0.0674 - dice_coef: 0.859 - ETA: 4:17 - loss: 0.0695 - dice_coef: 0.857 - ETA: 4:09 - loss: 0.0671 - dice_coef: 0.863 - ETA: 4:01 - loss: 0.0675 - dice_coef: 0.865 - ETA: 3:53 - loss: 0.0680 - dice_coef: 0.865 - ETA: 3:45 - loss: 0.0678 - dice_coef: 0.864 - ETA: 3:37 - loss: 0.0716 - dice_coef: 0.863 - ETA: 3:28 - loss: 0.0701 - dice_coef: 0.864 - ETA: 3:20 - loss: 0.0727 - dice_coef: 0.862 - ETA: 3:13 - loss: 0.0734 - dice_coef: 0.862 - ETA: 3:06 - loss: 0.0738 - dice_coef: 0.860 - ETA: 2:57 - loss: 0.0760 - dice_coef: 0.856 - ETA: 2:49 - loss: 0.0782 - dice_coef: 0.857 - ETA: 2:41 - loss: 0.0764 - dice_coef: 0.859 - ETA: 2:33 - loss: 0.0780 - dice_coef: 0.859 - ETA: 2:25 - loss: 0.0776 - dice_coef: 0.861 - ETA: 2:17 - loss: 0.0770 - dice_coef: 0.861 - ETA: 2:09 - loss: 0.0760 - dice_coef: 0.861 - ETA: 2:01 - loss: 0.0755 - dice_coef: 0.862 - ETA: 1:53 - loss: 0.0759 - dice_coef: 0.861 - ETA: 1:45 - loss: 0.0757 - dice_coef: 0.862 - ETA: 1:36 - loss: 0.0762 - dice_coef: 0.861 - ETA: 1:28 - loss: 0.0759 - dice_coef: 0.860 - ETA: 1:20 - loss: 0.0760 - dice_coef: 0.860 - ETA: 1:12 - loss: 0.0765 - dice_coef: 0.859 - ETA: 1:03 - loss: 0.0764 - dice_coef: 0.857 - ETA: 55s - loss: 0.0764 - dice_coef: 0.857 - ETA: 47s - loss: 0.0761 - dice_coef: 0.85 - ETA: 39s - loss: 0.0766 - dice_coef: 0.85 - ETA: 30s - loss: 0.0767 - dice_coef: 0.85 - ETA: 22s - loss: 0.0766 - dice_coef: 0.85 - ETA: 14s - loss: 0.0760 - dice_coef: 0.85 - ETA: 5s - loss: 0.0757 - dice_coef: 0.8555 - 326s 541ms/step - loss: 0.0752 - dice_coef: 0.8557 - val_loss: 0.0839 - val_dice_coef: 0.8366\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/50\n",
      "603/603 [==============================] - ETA: 5:10 - loss: 0.0680 - dice_coef: 0.866 - ETA: 5:02 - loss: 0.0643 - dice_coef: 0.869 - ETA: 4:52 - loss: 0.0717 - dice_coef: 0.864 - ETA: 4:44 - loss: 0.0710 - dice_coef: 0.858 - ETA: 4:35 - loss: 0.0737 - dice_coef: 0.850 - ETA: 4:27 - loss: 0.0719 - dice_coef: 0.857 - ETA: 4:18 - loss: 0.0740 - dice_coef: 0.858 - ETA: 4:11 - loss: 0.0734 - dice_coef: 0.858 - ETA: 4:02 - loss: 0.0714 - dice_coef: 0.855 - ETA: 3:54 - loss: 0.0705 - dice_coef: 0.857 - ETA: 3:46 - loss: 0.0737 - dice_coef: 0.854 - ETA: 3:37 - loss: 0.0738 - dice_coef: 0.856 - ETA: 3:29 - loss: 0.0733 - dice_coef: 0.858 - ETA: 3:21 - loss: 0.0724 - dice_coef: 0.859 - ETA: 3:13 - loss: 0.0724 - dice_coef: 0.859 - ETA: 3:05 - loss: 0.0719 - dice_coef: 0.861 - ETA: 2:56 - loss: 0.0712 - dice_coef: 0.861 - ETA: 2:48 - loss: 0.0755 - dice_coef: 0.858 - ETA: 2:39 - loss: 0.0756 - dice_coef: 0.857 - ETA: 2:31 - loss: 0.0754 - dice_coef: 0.857 - ETA: 2:22 - loss: 0.0747 - dice_coef: 0.858 - ETA: 2:13 - loss: 0.0763 - dice_coef: 0.858 - ETA: 2:05 - loss: 0.0769 - dice_coef: 0.858 - ETA: 1:57 - loss: 0.0766 - dice_coef: 0.856 - ETA: 1:48 - loss: 0.0755 - dice_coef: 0.856 - ETA: 1:40 - loss: 0.0752 - dice_coef: 0.857 - ETA: 1:32 - loss: 0.0746 - dice_coef: 0.857 - ETA: 1:23 - loss: 0.0749 - dice_coef: 0.856 - ETA: 1:14 - loss: 0.0754 - dice_coef: 0.857 - ETA: 1:06 - loss: 0.0755 - dice_coef: 0.857 - ETA: 57s - loss: 0.0752 - dice_coef: 0.857 - ETA: 48s - loss: 0.0753 - dice_coef: 0.85 - ETA: 40s - loss: 0.0747 - dice_coef: 0.85 - ETA: 31s - loss: 0.0747 - dice_coef: 0.85 - ETA: 23s - loss: 0.0749 - dice_coef: 0.85 - ETA: 14s - loss: 0.0748 - dice_coef: 0.85 - ETA: 5s - loss: 0.0744 - dice_coef: 0.8569 - 336s 558ms/step - loss: 0.0753 - dice_coef: 0.8569 - val_loss: 0.0762 - val_dice_coef: 0.8554\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.07856 to 0.07622, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 22/50\n",
      "603/603 [==============================] - ETA: 5:09 - loss: 0.0787 - dice_coef: 0.842 - ETA: 5:17 - loss: 0.1004 - dice_coef: 0.839 - ETA: 5:13 - loss: 0.0947 - dice_coef: 0.843 - ETA: 5:05 - loss: 0.0835 - dice_coef: 0.850 - ETA: 4:52 - loss: 0.0853 - dice_coef: 0.848 - ETA: 4:42 - loss: 0.0868 - dice_coef: 0.840 - ETA: 4:32 - loss: 0.0836 - dice_coef: 0.844 - ETA: 4:22 - loss: 0.0806 - dice_coef: 0.847 - ETA: 4:12 - loss: 0.0842 - dice_coef: 0.844 - ETA: 4:02 - loss: 0.0854 - dice_coef: 0.845 - ETA: 3:53 - loss: 0.0845 - dice_coef: 0.845 - ETA: 3:44 - loss: 0.0836 - dice_coef: 0.844 - ETA: 3:36 - loss: 0.0834 - dice_coef: 0.846 - ETA: 3:27 - loss: 0.0821 - dice_coef: 0.848 - ETA: 3:18 - loss: 0.0805 - dice_coef: 0.850 - ETA: 3:09 - loss: 0.0791 - dice_coef: 0.852 - ETA: 3:00 - loss: 0.0782 - dice_coef: 0.853 - ETA: 2:51 - loss: 0.0779 - dice_coef: 0.854 - ETA: 2:42 - loss: 0.0783 - dice_coef: 0.853 - ETA: 2:33 - loss: 0.0804 - dice_coef: 0.853 - ETA: 2:24 - loss: 0.0801 - dice_coef: 0.852 - ETA: 2:15 - loss: 0.0811 - dice_coef: 0.851 - ETA: 2:06 - loss: 0.0813 - dice_coef: 0.851 - ETA: 1:58 - loss: 0.0811 - dice_coef: 0.850 - ETA: 1:49 - loss: 0.0826 - dice_coef: 0.849 - ETA: 1:40 - loss: 0.0870 - dice_coef: 0.843 - ETA: 1:32 - loss: 0.0889 - dice_coef: 0.840 - ETA: 1:23 - loss: 0.0897 - dice_coef: 0.835 - ETA: 1:14 - loss: 0.0911 - dice_coef: 0.831 - ETA: 1:06 - loss: 0.0917 - dice_coef: 0.825 - ETA: 57s - loss: 0.0911 - dice_coef: 0.826 - ETA: 49s - loss: 0.0913 - dice_coef: 0.82 - ETA: 40s - loss: 0.0914 - dice_coef: 0.82 - ETA: 31s - loss: 0.0919 - dice_coef: 0.82 - ETA: 23s - loss: 0.0918 - dice_coef: 0.82 - ETA: 14s - loss: 0.0924 - dice_coef: 0.82 - ETA: 5s - loss: 0.0917 - dice_coef: 0.8260 - 336s 557ms/step - loss: 0.0909 - dice_coef: 0.8274 - val_loss: 0.0906 - val_dice_coef: 0.8332\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/50\n",
      "603/603 [==============================] - ETA: 5:17 - loss: 0.1036 - dice_coef: 0.788 - ETA: 5:13 - loss: 0.0885 - dice_coef: 0.810 - ETA: 5:05 - loss: 0.0958 - dice_coef: 0.819 - ETA: 4:57 - loss: 0.0913 - dice_coef: 0.832 - ETA: 4:46 - loss: 0.0860 - dice_coef: 0.842 - ETA: 4:36 - loss: 0.0828 - dice_coef: 0.845 - ETA: 4:26 - loss: 0.0817 - dice_coef: 0.847 - ETA: 4:16 - loss: 0.0803 - dice_coef: 0.847 - ETA: 4:08 - loss: 0.0885 - dice_coef: 0.840 - ETA: 3:58 - loss: 0.0874 - dice_coef: 0.843 - ETA: 3:49 - loss: 0.0877 - dice_coef: 0.840 - ETA: 3:40 - loss: 0.0928 - dice_coef: 0.837 - ETA: 3:32 - loss: 0.0945 - dice_coef: 0.833 - ETA: 3:23 - loss: 0.0934 - dice_coef: 0.834 - ETA: 3:14 - loss: 0.0919 - dice_coef: 0.835 - ETA: 3:05 - loss: 0.0893 - dice_coef: 0.836 - ETA: 2:56 - loss: 0.0887 - dice_coef: 0.833 - ETA: 2:48 - loss: 0.0892 - dice_coef: 0.833 - ETA: 2:39 - loss: 0.0881 - dice_coef: 0.835 - ETA: 2:30 - loss: 0.0880 - dice_coef: 0.835 - ETA: 2:22 - loss: 0.0890 - dice_coef: 0.835 - ETA: 2:13 - loss: 0.0884 - dice_coef: 0.837 - ETA: 2:05 - loss: 0.0890 - dice_coef: 0.835 - ETA: 1:56 - loss: 0.0893 - dice_coef: 0.835 - ETA: 1:48 - loss: 0.0886 - dice_coef: 0.836 - ETA: 1:39 - loss: 0.0878 - dice_coef: 0.836 - ETA: 1:31 - loss: 0.0875 - dice_coef: 0.836 - ETA: 1:22 - loss: 0.0876 - dice_coef: 0.836 - ETA: 1:14 - loss: 0.0872 - dice_coef: 0.836 - ETA: 1:05 - loss: 0.0866 - dice_coef: 0.837 - ETA: 57s - loss: 0.0861 - dice_coef: 0.836 - ETA: 48s - loss: 0.0863 - dice_coef: 0.83 - ETA: 39s - loss: 0.0858 - dice_coef: 0.83 - ETA: 31s - loss: 0.0864 - dice_coef: 0.83 - ETA: 22s - loss: 0.0862 - dice_coef: 0.83 - ETA: 14s - loss: 0.0860 - dice_coef: 0.84 - ETA: 5s - loss: 0.0853 - dice_coef: 0.8412 - 333s 552ms/step - loss: 0.0845 - dice_coef: 0.8421 - val_loss: 0.0880 - val_dice_coef: 0.8494\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - ETA: 5:30 - loss: 0.0821 - dice_coef: 0.811 - ETA: 5:16 - loss: 0.0780 - dice_coef: 0.812 - ETA: 5:02 - loss: 0.0736 - dice_coef: 0.840 - ETA: 4:52 - loss: 0.0683 - dice_coef: 0.850 - ETA: 4:41 - loss: 0.0775 - dice_coef: 0.843 - ETA: 4:32 - loss: 0.0756 - dice_coef: 0.843 - ETA: 4:22 - loss: 0.0729 - dice_coef: 0.851 - ETA: 4:13 - loss: 0.0730 - dice_coef: 0.853 - ETA: 4:05 - loss: 0.0717 - dice_coef: 0.854 - ETA: 3:56 - loss: 0.0744 - dice_coef: 0.857 - ETA: 3:47 - loss: 0.0731 - dice_coef: 0.859 - ETA: 3:39 - loss: 0.0731 - dice_coef: 0.858 - ETA: 3:30 - loss: 0.0751 - dice_coef: 0.859 - ETA: 3:22 - loss: 0.0763 - dice_coef: 0.855 - ETA: 3:13 - loss: 0.0741 - dice_coef: 0.858 - ETA: 3:05 - loss: 0.0744 - dice_coef: 0.858 - ETA: 2:56 - loss: 0.0749 - dice_coef: 0.859 - ETA: 2:48 - loss: 0.0761 - dice_coef: 0.858 - ETA: 2:39 - loss: 0.0758 - dice_coef: 0.858 - ETA: 2:30 - loss: 0.0754 - dice_coef: 0.858 - ETA: 2:22 - loss: 0.0774 - dice_coef: 0.857 - ETA: 2:13 - loss: 0.0798 - dice_coef: 0.856 - ETA: 2:05 - loss: 0.0784 - dice_coef: 0.856 - ETA: 1:56 - loss: 0.0775 - dice_coef: 0.856 - ETA: 1:48 - loss: 0.0771 - dice_coef: 0.857 - ETA: 1:39 - loss: 0.0767 - dice_coef: 0.859 - ETA: 1:30 - loss: 0.0770 - dice_coef: 0.857 - ETA: 1:22 - loss: 0.0766 - dice_coef: 0.856 - ETA: 1:13 - loss: 0.0762 - dice_coef: 0.856 - ETA: 1:05 - loss: 0.0759 - dice_coef: 0.855 - ETA: 56s - loss: 0.0764 - dice_coef: 0.854 - ETA: 48s - loss: 0.0758 - dice_coef: 0.85 - ETA: 39s - loss: 0.0764 - dice_coef: 0.85 - ETA: 31s - loss: 0.0778 - dice_coef: 0.85 - ETA: 22s - loss: 0.0774 - dice_coef: 0.85 - ETA: 14s - loss: 0.0771 - dice_coef: 0.85 - ETA: 5s - loss: 0.0769 - dice_coef: 0.8550 - 332s 551ms/step - loss: 0.0772 - dice_coef: 0.8549 - val_loss: 0.0763 - val_dice_coef: 0.8473\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/50\n",
      "603/603 [==============================] - ETA: 5:07 - loss: 0.0573 - dice_coef: 0.865 - ETA: 4:59 - loss: 0.0610 - dice_coef: 0.876 - ETA: 4:51 - loss: 0.0578 - dice_coef: 0.875 - ETA: 4:42 - loss: 0.0690 - dice_coef: 0.867 - ETA: 4:35 - loss: 0.0723 - dice_coef: 0.866 - ETA: 4:26 - loss: 0.0707 - dice_coef: 0.864 - ETA: 4:18 - loss: 0.0766 - dice_coef: 0.860 - ETA: 4:10 - loss: 0.0788 - dice_coef: 0.857 - ETA: 4:01 - loss: 0.0824 - dice_coef: 0.851 - ETA: 3:53 - loss: 0.0825 - dice_coef: 0.852 - ETA: 3:45 - loss: 0.0838 - dice_coef: 0.853 - ETA: 3:37 - loss: 0.0823 - dice_coef: 0.854 - ETA: 3:29 - loss: 0.0814 - dice_coef: 0.856 - ETA: 3:20 - loss: 0.0794 - dice_coef: 0.858 - ETA: 3:12 - loss: 0.0784 - dice_coef: 0.857 - ETA: 3:03 - loss: 0.0799 - dice_coef: 0.856 - ETA: 2:55 - loss: 0.0791 - dice_coef: 0.857 - ETA: 2:47 - loss: 0.0789 - dice_coef: 0.857 - ETA: 2:39 - loss: 0.0781 - dice_coef: 0.856 - ETA: 2:31 - loss: 0.0783 - dice_coef: 0.854 - ETA: 2:22 - loss: 0.0779 - dice_coef: 0.854 - ETA: 2:14 - loss: 0.0774 - dice_coef: 0.854 - ETA: 2:05 - loss: 0.0778 - dice_coef: 0.854 - ETA: 1:57 - loss: 0.0761 - dice_coef: 0.857 - ETA: 1:48 - loss: 0.0755 - dice_coef: 0.857 - ETA: 1:39 - loss: 0.0752 - dice_coef: 0.857 - ETA: 1:30 - loss: 0.0748 - dice_coef: 0.858 - ETA: 1:22 - loss: 0.0743 - dice_coef: 0.859 - ETA: 1:13 - loss: 0.0753 - dice_coef: 0.858 - ETA: 1:05 - loss: 0.0753 - dice_coef: 0.857 - ETA: 56s - loss: 0.0765 - dice_coef: 0.857 - ETA: 48s - loss: 0.0765 - dice_coef: 0.85 - ETA: 39s - loss: 0.0758 - dice_coef: 0.85 - ETA: 31s - loss: 0.0755 - dice_coef: 0.85 - ETA: 22s - loss: 0.0756 - dice_coef: 0.85 - ETA: 14s - loss: 0.0751 - dice_coef: 0.85 - ETA: 5s - loss: 0.0746 - dice_coef: 0.8585 - 331s 548ms/step - loss: 0.0738 - dice_coef: 0.8596 - val_loss: 0.0753 - val_dice_coef: 0.8452\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.07622 to 0.07526, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 26/50\n",
      "603/603 [==============================] - ETA: 5:09 - loss: 0.0525 - dice_coef: 0.873 - ETA: 5:00 - loss: 0.0623 - dice_coef: 0.866 - ETA: 4:52 - loss: 0.0565 - dice_coef: 0.870 - ETA: 4:43 - loss: 0.0603 - dice_coef: 0.869 - ETA: 4:35 - loss: 0.0663 - dice_coef: 0.868 - ETA: 4:26 - loss: 0.0627 - dice_coef: 0.869 - ETA: 4:19 - loss: 0.0614 - dice_coef: 0.869 - ETA: 4:10 - loss: 0.0602 - dice_coef: 0.870 - ETA: 4:02 - loss: 0.0603 - dice_coef: 0.872 - ETA: 3:53 - loss: 0.0628 - dice_coef: 0.871 - ETA: 3:45 - loss: 0.0644 - dice_coef: 0.870 - ETA: 3:37 - loss: 0.0681 - dice_coef: 0.870 - ETA: 3:29 - loss: 0.0677 - dice_coef: 0.870 - ETA: 3:20 - loss: 0.0699 - dice_coef: 0.871 - ETA: 3:11 - loss: 0.0702 - dice_coef: 0.871 - ETA: 3:03 - loss: 0.0692 - dice_coef: 0.872 - ETA: 2:54 - loss: 0.0687 - dice_coef: 0.873 - ETA: 2:46 - loss: 0.0677 - dice_coef: 0.872 - ETA: 2:37 - loss: 0.0678 - dice_coef: 0.872 - ETA: 2:29 - loss: 0.0680 - dice_coef: 0.870 - ETA: 2:20 - loss: 0.0669 - dice_coef: 0.869 - ETA: 2:12 - loss: 0.0668 - dice_coef: 0.869 - ETA: 2:03 - loss: 0.0660 - dice_coef: 0.869 - ETA: 1:55 - loss: 0.0658 - dice_coef: 0.870 - ETA: 1:47 - loss: 0.0669 - dice_coef: 0.870 - ETA: 1:38 - loss: 0.0673 - dice_coef: 0.869 - ETA: 1:30 - loss: 0.0673 - dice_coef: 0.869 - ETA: 1:21 - loss: 0.0683 - dice_coef: 0.867 - ETA: 1:13 - loss: 0.0696 - dice_coef: 0.867 - ETA: 1:05 - loss: 0.0701 - dice_coef: 0.867 - ETA: 56s - loss: 0.0708 - dice_coef: 0.866 - ETA: 48s - loss: 0.0715 - dice_coef: 0.86 - ETA: 39s - loss: 0.0713 - dice_coef: 0.86 - ETA: 31s - loss: 0.0720 - dice_coef: 0.86 - ETA: 22s - loss: 0.0721 - dice_coef: 0.86 - ETA: 14s - loss: 0.0722 - dice_coef: 0.86 - ETA: 5s - loss: 0.0718 - dice_coef: 0.8633 - 330s 548ms/step - loss: 0.0716 - dice_coef: 0.8629 - val_loss: 0.0740 - val_dice_coef: 0.8456\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.07526 to 0.07396, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 27/50\n",
      "603/603 [==============================] - ETA: 5:05 - loss: 0.0668 - dice_coef: 0.865 - ETA: 5:00 - loss: 0.0576 - dice_coef: 0.880 - ETA: 4:50 - loss: 0.0696 - dice_coef: 0.859 - ETA: 4:43 - loss: 0.0732 - dice_coef: 0.862 - ETA: 4:34 - loss: 0.0673 - dice_coef: 0.869 - ETA: 4:26 - loss: 0.0652 - dice_coef: 0.871 - ETA: 4:17 - loss: 0.0667 - dice_coef: 0.862 - ETA: 4:09 - loss: 0.0655 - dice_coef: 0.860 - ETA: 4:01 - loss: 0.0654 - dice_coef: 0.864 - ETA: 3:53 - loss: 0.0684 - dice_coef: 0.860 - ETA: 3:44 - loss: 0.0732 - dice_coef: 0.860 - ETA: 3:36 - loss: 0.0735 - dice_coef: 0.860 - ETA: 3:28 - loss: 0.0737 - dice_coef: 0.857 - ETA: 3:20 - loss: 0.0749 - dice_coef: 0.856 - ETA: 3:13 - loss: 0.0765 - dice_coef: 0.856 - ETA: 3:05 - loss: 0.0784 - dice_coef: 0.855 - ETA: 2:57 - loss: 0.0766 - dice_coef: 0.855 - ETA: 2:48 - loss: 0.0771 - dice_coef: 0.854 - ETA: 2:40 - loss: 0.0764 - dice_coef: 0.855 - ETA: 2:31 - loss: 0.0762 - dice_coef: 0.856 - ETA: 2:23 - loss: 0.0752 - dice_coef: 0.857 - ETA: 2:14 - loss: 0.0743 - dice_coef: 0.855 - ETA: 2:06 - loss: 0.0737 - dice_coef: 0.855 - ETA: 1:57 - loss: 0.0737 - dice_coef: 0.854 - ETA: 1:48 - loss: 0.0727 - dice_coef: 0.856 - ETA: 1:40 - loss: 0.0727 - dice_coef: 0.857 - ETA: 1:31 - loss: 0.0725 - dice_coef: 0.858 - ETA: 1:23 - loss: 0.0727 - dice_coef: 0.857 - ETA: 1:14 - loss: 0.0718 - dice_coef: 0.858 - ETA: 1:05 - loss: 0.0722 - dice_coef: 0.858 - ETA: 57s - loss: 0.0722 - dice_coef: 0.858 - ETA: 48s - loss: 0.0720 - dice_coef: 0.85 - ETA: 40s - loss: 0.0714 - dice_coef: 0.86 - ETA: 31s - loss: 0.0712 - dice_coef: 0.86 - ETA: 22s - loss: 0.0710 - dice_coef: 0.86 - ETA: 14s - loss: 0.0712 - dice_coef: 0.86 - ETA: 5s - loss: 0.0714 - dice_coef: 0.8617 - 334s 553ms/step - loss: 0.0718 - dice_coef: 0.8617 - val_loss: 0.0784 - val_dice_coef: 0.8474\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - ETA: 5:11 - loss: 0.0670 - dice_coef: 0.852 - ETA: 5:05 - loss: 0.0645 - dice_coef: 0.861 - ETA: 4:56 - loss: 0.0627 - dice_coef: 0.864 - ETA: 4:47 - loss: 0.0711 - dice_coef: 0.852 - ETA: 4:37 - loss: 0.0738 - dice_coef: 0.852 - ETA: 4:29 - loss: 0.0687 - dice_coef: 0.857 - ETA: 4:20 - loss: 0.0671 - dice_coef: 0.858 - ETA: 4:12 - loss: 0.0664 - dice_coef: 0.859 - ETA: 4:03 - loss: 0.0710 - dice_coef: 0.859 - ETA: 3:55 - loss: 0.0699 - dice_coef: 0.856 - ETA: 3:46 - loss: 0.0691 - dice_coef: 0.861 - ETA: 3:38 - loss: 0.0675 - dice_coef: 0.863 - ETA: 3:29 - loss: 0.0686 - dice_coef: 0.860 - ETA: 3:20 - loss: 0.0705 - dice_coef: 0.858 - ETA: 3:12 - loss: 0.0704 - dice_coef: 0.858 - ETA: 3:03 - loss: 0.0714 - dice_coef: 0.857 - ETA: 2:55 - loss: 0.0699 - dice_coef: 0.857 - ETA: 2:46 - loss: 0.0703 - dice_coef: 0.857 - ETA: 2:38 - loss: 0.0706 - dice_coef: 0.859 - ETA: 2:29 - loss: 0.0695 - dice_coef: 0.861 - ETA: 2:21 - loss: 0.0697 - dice_coef: 0.860 - ETA: 2:12 - loss: 0.0694 - dice_coef: 0.862 - ETA: 2:04 - loss: 0.0684 - dice_coef: 0.862 - ETA: 1:55 - loss: 0.0695 - dice_coef: 0.862 - ETA: 1:47 - loss: 0.0690 - dice_coef: 0.863 - ETA: 1:38 - loss: 0.0691 - dice_coef: 0.863 - ETA: 1:30 - loss: 0.0685 - dice_coef: 0.864 - ETA: 1:21 - loss: 0.0684 - dice_coef: 0.864 - ETA: 1:13 - loss: 0.0687 - dice_coef: 0.865 - ETA: 1:05 - loss: 0.0695 - dice_coef: 0.865 - ETA: 56s - loss: 0.0692 - dice_coef: 0.865 - ETA: 48s - loss: 0.0708 - dice_coef: 0.86 - ETA: 39s - loss: 0.0723 - dice_coef: 0.86 - ETA: 31s - loss: 0.0732 - dice_coef: 0.86 - ETA: 22s - loss: 0.0729 - dice_coef: 0.86 - ETA: 14s - loss: 0.0725 - dice_coef: 0.86 - ETA: 5s - loss: 0.0724 - dice_coef: 0.8621 - 331s 550ms/step - loss: 0.0720 - dice_coef: 0.8621 - val_loss: 0.0707 - val_dice_coef: 0.8424\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.07396 to 0.07068, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 29/50\n",
      "603/603 [==============================] - ETA: 5:06 - loss: 0.0689 - dice_coef: 0.830 - ETA: 5:00 - loss: 0.0859 - dice_coef: 0.804 - ETA: 4:54 - loss: 0.0817 - dice_coef: 0.815 - ETA: 4:43 - loss: 0.0795 - dice_coef: 0.826 - ETA: 4:34 - loss: 0.0712 - dice_coef: 0.840 - ETA: 4:24 - loss: 0.0699 - dice_coef: 0.846 - ETA: 4:17 - loss: 0.0691 - dice_coef: 0.849 - ETA: 4:09 - loss: 0.0677 - dice_coef: 0.855 - ETA: 4:05 - loss: 0.0689 - dice_coef: 0.857 - ETA: 3:59 - loss: 0.0692 - dice_coef: 0.855 - ETA: 3:53 - loss: 0.0694 - dice_coef: 0.855 - ETA: 3:44 - loss: 0.0688 - dice_coef: 0.859 - ETA: 3:35 - loss: 0.0716 - dice_coef: 0.859 - ETA: 3:27 - loss: 0.0733 - dice_coef: 0.859 - ETA: 3:19 - loss: 0.0726 - dice_coef: 0.862 - ETA: 3:10 - loss: 0.0721 - dice_coef: 0.863 - ETA: 3:01 - loss: 0.0737 - dice_coef: 0.861 - ETA: 2:53 - loss: 0.0734 - dice_coef: 0.860 - ETA: 2:44 - loss: 0.0727 - dice_coef: 0.859 - ETA: 2:35 - loss: 0.0731 - dice_coef: 0.860 - ETA: 2:26 - loss: 0.0733 - dice_coef: 0.859 - ETA: 2:17 - loss: 0.0732 - dice_coef: 0.858 - ETA: 2:08 - loss: 0.0728 - dice_coef: 0.858 - ETA: 1:59 - loss: 0.0722 - dice_coef: 0.859 - ETA: 1:50 - loss: 0.0716 - dice_coef: 0.859 - ETA: 1:41 - loss: 0.0711 - dice_coef: 0.861 - ETA: 1:32 - loss: 0.0717 - dice_coef: 0.860 - ETA: 1:23 - loss: 0.0713 - dice_coef: 0.861 - ETA: 1:15 - loss: 0.0718 - dice_coef: 0.862 - ETA: 1:06 - loss: 0.0722 - dice_coef: 0.862 - ETA: 57s - loss: 0.0743 - dice_coef: 0.860 - ETA: 48s - loss: 0.0736 - dice_coef: 0.86 - ETA: 40s - loss: 0.0728 - dice_coef: 0.86 - ETA: 31s - loss: 0.0731 - dice_coef: 0.86 - ETA: 22s - loss: 0.0730 - dice_coef: 0.86 - ETA: 14s - loss: 0.0724 - dice_coef: 0.86 - ETA: 5s - loss: 0.0716 - dice_coef: 0.8636 - 333s 552ms/step - loss: 0.0714 - dice_coef: 0.8633 - val_loss: 0.0708 - val_dice_coef: 0.8461\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/50\n",
      "603/603 [==============================] - ETA: 4:56 - loss: 0.0718 - dice_coef: 0.845 - ETA: 4:55 - loss: 0.0689 - dice_coef: 0.863 - ETA: 4:50 - loss: 0.0645 - dice_coef: 0.867 - ETA: 4:43 - loss: 0.0618 - dice_coef: 0.865 - ETA: 4:35 - loss: 0.0617 - dice_coef: 0.862 - ETA: 4:27 - loss: 0.0616 - dice_coef: 0.857 - ETA: 4:19 - loss: 0.0644 - dice_coef: 0.858 - ETA: 4:10 - loss: 0.0659 - dice_coef: 0.858 - ETA: 4:02 - loss: 0.0657 - dice_coef: 0.859 - ETA: 3:53 - loss: 0.0652 - dice_coef: 0.864 - ETA: 3:45 - loss: 0.0676 - dice_coef: 0.862 - ETA: 3:37 - loss: 0.0681 - dice_coef: 0.864 - ETA: 3:28 - loss: 0.0673 - dice_coef: 0.865 - ETA: 3:20 - loss: 0.0676 - dice_coef: 0.866 - ETA: 3:11 - loss: 0.0672 - dice_coef: 0.865 - ETA: 3:03 - loss: 0.0661 - dice_coef: 0.867 - ETA: 2:54 - loss: 0.0665 - dice_coef: 0.868 - ETA: 2:46 - loss: 0.0672 - dice_coef: 0.866 - ETA: 2:37 - loss: 0.0698 - dice_coef: 0.866 - ETA: 2:29 - loss: 0.0705 - dice_coef: 0.866 - ETA: 2:20 - loss: 0.0715 - dice_coef: 0.865 - ETA: 2:12 - loss: 0.0715 - dice_coef: 0.864 - ETA: 2:03 - loss: 0.0724 - dice_coef: 0.862 - ETA: 1:55 - loss: 0.0721 - dice_coef: 0.862 - ETA: 1:46 - loss: 0.0717 - dice_coef: 0.863 - ETA: 1:38 - loss: 0.0716 - dice_coef: 0.863 - ETA: 1:30 - loss: 0.0723 - dice_coef: 0.862 - ETA: 1:21 - loss: 0.0720 - dice_coef: 0.862 - ETA: 1:13 - loss: 0.0725 - dice_coef: 0.862 - ETA: 1:05 - loss: 0.0724 - dice_coef: 0.861 - ETA: 56s - loss: 0.0718 - dice_coef: 0.860 - ETA: 48s - loss: 0.0719 - dice_coef: 0.86 - ETA: 39s - loss: 0.0718 - dice_coef: 0.86 - ETA: 31s - loss: 0.0720 - dice_coef: 0.86 - ETA: 22s - loss: 0.0719 - dice_coef: 0.86 - ETA: 14s - loss: 0.0717 - dice_coef: 0.86 - ETA: 5s - loss: 0.0717 - dice_coef: 0.8601 - 334s 554ms/step - loss: 0.0712 - dice_coef: 0.8611 - val_loss: 0.0738 - val_dice_coef: 0.8588\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/50\n",
      "603/603 [==============================] - ETA: 5:04 - loss: 0.0417 - dice_coef: 0.909 - ETA: 4:58 - loss: 0.0639 - dice_coef: 0.895 - ETA: 4:50 - loss: 0.0587 - dice_coef: 0.882 - ETA: 4:42 - loss: 0.0603 - dice_coef: 0.884 - ETA: 4:33 - loss: 0.0686 - dice_coef: 0.880 - ETA: 4:26 - loss: 0.0650 - dice_coef: 0.882 - ETA: 4:17 - loss: 0.0656 - dice_coef: 0.876 - ETA: 4:09 - loss: 0.0634 - dice_coef: 0.873 - ETA: 4:01 - loss: 0.0649 - dice_coef: 0.874 - ETA: 3:52 - loss: 0.0666 - dice_coef: 0.870 - ETA: 3:44 - loss: 0.0692 - dice_coef: 0.869 - ETA: 3:35 - loss: 0.0702 - dice_coef: 0.867 - ETA: 3:27 - loss: 0.0709 - dice_coef: 0.865 - ETA: 3:19 - loss: 0.0717 - dice_coef: 0.865 - ETA: 3:11 - loss: 0.0717 - dice_coef: 0.865 - ETA: 3:04 - loss: 0.0724 - dice_coef: 0.862 - ETA: 2:56 - loss: 0.0733 - dice_coef: 0.862 - ETA: 2:49 - loss: 0.0729 - dice_coef: 0.863 - ETA: 2:41 - loss: 0.0724 - dice_coef: 0.864 - ETA: 2:32 - loss: 0.0715 - dice_coef: 0.864 - ETA: 2:24 - loss: 0.0719 - dice_coef: 0.863 - ETA: 2:15 - loss: 0.0700 - dice_coef: 0.864 - ETA: 2:06 - loss: 0.0687 - dice_coef: 0.866 - ETA: 1:57 - loss: 0.0683 - dice_coef: 0.866 - ETA: 1:49 - loss: 0.0684 - dice_coef: 0.867 - ETA: 1:40 - loss: 0.0687 - dice_coef: 0.866 - ETA: 1:31 - loss: 0.0687 - dice_coef: 0.868 - ETA: 1:23 - loss: 0.0687 - dice_coef: 0.867 - ETA: 1:14 - loss: 0.0692 - dice_coef: 0.867 - ETA: 1:05 - loss: 0.0684 - dice_coef: 0.868 - ETA: 57s - loss: 0.0690 - dice_coef: 0.868 - ETA: 48s - loss: 0.0706 - dice_coef: 0.86 - ETA: 40s - loss: 0.0705 - dice_coef: 0.86 - ETA: 31s - loss: 0.0707 - dice_coef: 0.86 - ETA: 23s - loss: 0.0706 - dice_coef: 0.86 - ETA: 14s - loss: 0.0708 - dice_coef: 0.86 - ETA: 5s - loss: 0.0704 - dice_coef: 0.8660 - 335s 556ms/step - loss: 0.0704 - dice_coef: 0.8661 - val_loss: 0.0778 - val_dice_coef: 0.8455\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - ETA: 5:07 - loss: 0.0750 - dice_coef: 0.844 - ETA: 5:02 - loss: 0.0682 - dice_coef: 0.860 - ETA: 4:53 - loss: 0.0725 - dice_coef: 0.858 - ETA: 4:45 - loss: 0.0709 - dice_coef: 0.861 - ETA: 4:36 - loss: 0.0708 - dice_coef: 0.863 - ETA: 4:32 - loss: 0.0670 - dice_coef: 0.867 - ETA: 4:24 - loss: 0.0678 - dice_coef: 0.869 - ETA: 4:15 - loss: 0.0664 - dice_coef: 0.875 - ETA: 4:06 - loss: 0.0659 - dice_coef: 0.873 - ETA: 3:57 - loss: 0.0660 - dice_coef: 0.873 - ETA: 3:48 - loss: 0.0695 - dice_coef: 0.871 - ETA: 3:39 - loss: 0.0676 - dice_coef: 0.872 - ETA: 3:31 - loss: 0.0674 - dice_coef: 0.873 - ETA: 3:22 - loss: 0.0679 - dice_coef: 0.871 - ETA: 3:13 - loss: 0.0662 - dice_coef: 0.871 - ETA: 3:05 - loss: 0.0657 - dice_coef: 0.872 - ETA: 2:56 - loss: 0.0647 - dice_coef: 0.872 - ETA: 2:48 - loss: 0.0681 - dice_coef: 0.871 - ETA: 2:39 - loss: 0.0677 - dice_coef: 0.871 - ETA: 2:30 - loss: 0.0681 - dice_coef: 0.871 - ETA: 2:21 - loss: 0.0696 - dice_coef: 0.869 - ETA: 2:12 - loss: 0.0698 - dice_coef: 0.869 - ETA: 2:04 - loss: 0.0697 - dice_coef: 0.867 - ETA: 1:55 - loss: 0.0698 - dice_coef: 0.866 - ETA: 1:47 - loss: 0.0697 - dice_coef: 0.866 - ETA: 1:38 - loss: 0.0703 - dice_coef: 0.865 - ETA: 1:29 - loss: 0.0697 - dice_coef: 0.864 - ETA: 1:21 - loss: 0.0703 - dice_coef: 0.863 - ETA: 1:12 - loss: 0.0706 - dice_coef: 0.863 - ETA: 1:04 - loss: 0.0701 - dice_coef: 0.864 - ETA: 56s - loss: 0.0695 - dice_coef: 0.865 - ETA: 47s - loss: 0.0692 - dice_coef: 0.86 - ETA: 39s - loss: 0.0691 - dice_coef: 0.86 - ETA: 30s - loss: 0.0693 - dice_coef: 0.86 - ETA: 22s - loss: 0.0695 - dice_coef: 0.86 - ETA: 14s - loss: 0.0693 - dice_coef: 0.86 - ETA: 5s - loss: 0.0699 - dice_coef: 0.8657 - 325s 540ms/step - loss: 0.0698 - dice_coef: 0.8659 - val_loss: 0.0716 - val_dice_coef: 0.8541\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/50\n",
      "603/603 [==============================] - ETA: 5:00 - loss: 0.0973 - dice_coef: 0.858 - ETA: 4:50 - loss: 0.0703 - dice_coef: 0.889 - ETA: 4:43 - loss: 0.0627 - dice_coef: 0.892 - ETA: 4:34 - loss: 0.0690 - dice_coef: 0.885 - ETA: 4:26 - loss: 0.0707 - dice_coef: 0.872 - ETA: 4:18 - loss: 0.0679 - dice_coef: 0.872 - ETA: 4:10 - loss: 0.0667 - dice_coef: 0.871 - ETA: 4:01 - loss: 0.0726 - dice_coef: 0.866 - ETA: 3:53 - loss: 0.0699 - dice_coef: 0.868 - ETA: 3:45 - loss: 0.0685 - dice_coef: 0.870 - ETA: 3:37 - loss: 0.0677 - dice_coef: 0.870 - ETA: 3:29 - loss: 0.0668 - dice_coef: 0.870 - ETA: 3:21 - loss: 0.0657 - dice_coef: 0.870 - ETA: 3:12 - loss: 0.0639 - dice_coef: 0.871 - ETA: 3:04 - loss: 0.0633 - dice_coef: 0.871 - ETA: 2:56 - loss: 0.0668 - dice_coef: 0.869 - ETA: 2:48 - loss: 0.0658 - dice_coef: 0.871 - ETA: 2:40 - loss: 0.0654 - dice_coef: 0.872 - ETA: 2:32 - loss: 0.0666 - dice_coef: 0.872 - ETA: 2:24 - loss: 0.0669 - dice_coef: 0.871 - ETA: 2:16 - loss: 0.0667 - dice_coef: 0.873 - ETA: 2:08 - loss: 0.0658 - dice_coef: 0.873 - ETA: 2:00 - loss: 0.0661 - dice_coef: 0.869 - ETA: 1:52 - loss: 0.0669 - dice_coef: 0.869 - ETA: 1:44 - loss: 0.0664 - dice_coef: 0.868 - ETA: 1:36 - loss: 0.0670 - dice_coef: 0.868 - ETA: 1:28 - loss: 0.0687 - dice_coef: 0.866 - ETA: 1:19 - loss: 0.0687 - dice_coef: 0.866 - ETA: 1:11 - loss: 0.0679 - dice_coef: 0.866 - ETA: 1:03 - loss: 0.0676 - dice_coef: 0.866 - ETA: 55s - loss: 0.0678 - dice_coef: 0.866 - ETA: 47s - loss: 0.0685 - dice_coef: 0.86 - ETA: 38s - loss: 0.0692 - dice_coef: 0.86 - ETA: 30s - loss: 0.0694 - dice_coef: 0.86 - ETA: 22s - loss: 0.0694 - dice_coef: 0.86 - ETA: 13s - loss: 0.0702 - dice_coef: 0.86 - ETA: 5s - loss: 0.0698 - dice_coef: 0.8662 - 324s 538ms/step - loss: 0.0692 - dice_coef: 0.8667 - val_loss: 0.0709 - val_dice_coef: 0.8505\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 00033: early stopping\n",
      "603/603 [==============================] - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 54s - ETA: 49 - ETA: 43 - ETA: 38 - ETA: 32 - ETA: 26 - ETA: 21 - ETA: 15 - ETA: 10 - ETA: 4 - 105s 174ms/step\n",
      "67/67 [==============================] - ETA:  - ETA:  - 12s 174ms/step\n",
      "65/65 [==============================] - ETA:  - ETA:  - 11s 175ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x255f2710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-75815c0e8c7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_train_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(arr, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imshow'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\io\\manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                                (plugin, kind))\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(im, ax, show_cbar, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mdivider\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_axes_locatable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mcax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdivider\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"right\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"5%\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max_im\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_adjustable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'box-forced'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mcolorbar\u001b[1;34m(mappable, cax, ax, **kw)\u001b[0m\n\u001b[0;32m   2199\u001b[0m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2201\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmappable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2202\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2203\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar_doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mcolorbar\u001b[1;34m(self, mappable, cax, ax, use_gridspec, **kw)\u001b[0m\n\u001b[0;32m   1862\u001b[0m                 \u001b[0mcax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m         \u001b[0mcax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1864\u001b[1;33m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_ax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36mcolorbar_factory\u001b[1;34m(cax, mappable, **kwargs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mColorbarPatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mColorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[0mcid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmappable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacksSM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'changed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_mappable_changed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ax, mappable, **kw)\u001b[0m\n\u001b[0;32m    944\u001b[0m                 \u001b[0mkw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmappable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m             \u001b[0mColorbarBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_mappable_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;31m# The rest is in a method so we can recalculate when clim changes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_extend_lower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36mdraw_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    349\u001b[0m         '''\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mesh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m_process_values\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 expander=0.1)\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uniform_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mnonsingular\u001b[1;34m(vmin, vmax, expander, tiny, increasing)\u001b[0m\n\u001b[0;32m   2911\u001b[0m         \u001b[0mvmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpander\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2913\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0mvmax\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvmin\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mmaxabsvalue\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtiny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvmax\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvmin\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2915\u001b[0m             \u001b[0mvmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mexpander\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = 'G:/Kaggle_data/Kaggle_bowl/stage1_train/'\n",
    "TEST_PATH = 'G:/Kaggle_data/Kaggle_bowl/stage1_test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "smooth = 1\n",
    "\n",
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "\n",
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "    \n",
    "#def scale_img_canals(an_img):\n",
    "for i in range(IMG_CHANNELS):\n",
    "    canal = img[:,:,i]\n",
    "    canal = canal - canal.min()\n",
    "    canalmax = canal.max()\n",
    "    if canalmax > 0:\n",
    "        factor = 255/canalmax\n",
    "        canal = (canal * factor).astype(int)\n",
    "    img[:,:,i] = canal\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "    \n",
    "for i in range(IMG_CHANNELS):\n",
    "    canal = img[:,:,i]\n",
    "    canal = canal - canal.min()\n",
    "    canalmax = canal.max()\n",
    "    if canalmax > 0:\n",
    "        factor = 255/canalmax\n",
    "        canal = (canal * factor).astype(int)\n",
    "    img[:,:,i] = canal\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "\n",
    "# Define IoU metric\n",
    "\"\"\"def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\"\"\"\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
    "model.summary()\n",
    "\n",
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n",
    "                    callbacks=[earlystopper, checkpointer])\n",
    "\n",
    "# Predict on train, val and test\n",
    "model = load_model('model-dsbowl2018-1.h5', custom_objects={'dice_coef': dice_coef})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))\n",
    "    \n",
    "# Perform a sanity check on some random training samples\n",
    "# ix = random.randint(0, len(preds_train_t))\n",
    "# imshow(X_train[ix])\n",
    "# plt.show()\n",
    "# imshow(np.squeeze(Y_train[ix]))\n",
    "# plt.show()\n",
    "# imshow(np.squeeze(preds_train_t[ix]))\n",
    "# plt.show()\n",
    "\n",
    "# Perform a sanity check on some random validation samples\n",
    "# ix = random.randint(0, len(preds_val_t))\n",
    "# imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "# plt.show()\n",
    "# imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "# plt.show()\n",
    "# imshow(np.squeeze(preds_val_t[ix]))\n",
    "# plt.show()\n",
    "\n",
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)\n",
    "        \n",
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))\n",
    "    \n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('sub-dsbowl2018-1_17.03.2018_dice_256_scale.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)\n",
    "        \n",
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))\n",
    "    \n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('sub-dsbowl2018-1_17.03.2018_dice_256_scale.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
